"""
å®Œæ•´é›†æˆç¤ºä¾‹ï¼šäº”ä¸ªé˜¶æ®µçš„ååŒå·¥ä½œ
Complete Integration Example: All Five Stages Working Together

å±•ç¤ºå¦‚ä½•å°†æ‰€æœ‰é˜¶æ®µæ•´åˆåˆ°ä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒæµç¨‹ä¸­

æ›´æ–°æ—¥å¿— (v2.0):
- âœ… å®Œæ•´çš„ PCCheck é›†æˆæ”¯æŒ
- âœ… æ”¯æŒ Chk_monitor åå°è¿›ç¨‹æ¨¡å¼ï¼ˆæ›´é«˜æ•ˆï¼‰
- âœ… æ–°å¢å‚æ•°ï¼šnum_threads, max_async, batch_size_mb, ratio
- âœ… åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒï¼ˆis_distributed, rank, world_sizeï¼‰
- âœ… ä¸‰ç§å·¥ä½œæ¨¡å¼ï¼šMock / Checkpoint ç›´æ¥ / Monitor åå°è¿›ç¨‹

ä½¿ç”¨æ–¹å¼ï¼š
1. Mock æ¨¡å¼ï¼ˆæµ‹è¯•ï¼‰ï¼šuse_pccheck=False
2. Checkpoin    trainer = LayerwiseCheckpointTrainer(
        model, 
        optimizer,
        use_pccheck=True,         # ğŸ”¥ å¯ç”¨çœŸå® PCCheck
        use_monitor=False,        # ğŸ“Œ ç›´æ¥æ¨¡å¼ï¼ˆæˆ–æ”¹ä¸º True ä½¿ç”¨ Monitorï¼‰
        num_threads=8,            # âš¡ 8 ä¸ªå†™å…¥çº¿ç¨‹
        max_async=4,              # ğŸ“¦ æœ€å¤š 4 ä¸ªå¹¶å‘æ£€æŸ¥ç‚¹ï¼ˆè¶³å¤Ÿå®¹çº³å¤šæ¬¡ä¿å­˜ï¼‰
        batch_size_mb=100.0,      # ğŸ’¾ æ¯æ‰¹ 100MB
        ratio=2.0,                # ğŸ”§ 2å€ CPU ç¼“å†²åŒº
        checkpoint_dir="./layerwise_checkpoints"
    )ck=True, use_monitor=False
3. Monitor æ¨¡å¼ï¼ˆæ¨èï¼‰ï¼šuse_pccheck=True, use_monitor=True
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset
import sys
import os
import time

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from layer_dependency_graph import DependencyGraphBuilder
from layerwise_optimizer import LayerwiseOptimizer
from layerwise_scheduler import LayerwiseCheckpointScheduler
from pccheck_adapter import PCCheckAdapter
from checkpoint_metadata import CheckpointMetadataManager, ModelRecovery
from pccheck_utils import initialize, set_storage


# ============================================================================
# å®šä¹‰æµ‹è¯•æ¨¡å‹
# ============================================================================

class SimpleCNN(nn.Module):
    """ç®€å•çš„ CNN æ¨¡å‹ç”¨äºæµ‹è¯•"""
    def __init__(self, num_classes=10):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(32)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(64)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(64 * 8 * 8, 128)
        self.fc2 = nn.Linear(128, num_classes)
    
    def forward(self, x):
        x = self.pool(F.relu(self.bn1(self.conv1(x))))
        x = self.pool(F.relu(self.bn2(self.conv2(x))))
        x = torch.flatten(x, 1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x


# ============================================================================
# å®Œæ•´çš„è®­ç»ƒç³»ç»Ÿé›†æˆç±»
# ============================================================================

class LayerwiseCheckpointTrainer:
    """
    é›†æˆäº†åˆ†å±‚æ£€æŸ¥ç‚¹çš„è®­ç»ƒå™¨
    
    æ•´åˆæ‰€æœ‰äº”ä¸ªé˜¶æ®µï¼š
    1. ä¾èµ–åˆ†æ (DependencyGraphBuilder)
    2. åˆ†å±‚ä¼˜åŒ–å™¨ (LayerwiseOptimizer)
    3. è°ƒåº¦å™¨ (LayerwiseCheckpointScheduler)
    4. PCCheck é€‚é…å™¨ (PCCheckAdapter)
    5. å…ƒæ•°æ®ç®¡ç† (CheckpointMetadataManager)
    """
    
    def __init__(
        self,
        model: nn.Module,
        optimizer_class,
        optimizer_kwargs: dict,
        checkpoint_dir: str = "./layerwise_checkpoints",
        buffer_size_mb: float = 50.0,
        checkpoint_chunk_count: int = 3,
        use_pccheck: bool = False,
        use_monitor: bool = False,
        num_threads: int = 8,
        max_async: int = 2,
        batch_size_mb: float = 100.0,
        ratio: float = 2.0,
        c_lib_path: str = None,
        is_distributed: bool = False,
        rank: int = 0,
        world_size: int = 1,
        device: str = 'cuda' if torch.cuda.is_available() else 'cpu',
        verbose: bool = True
    ):
        """
        Args:
            model: PyTorch æ¨¡å‹
            optimizer_class: ä¼˜åŒ–å™¨ç±»ï¼ˆå¦‚ torch.optim.Adamï¼‰
            optimizer_kwargs: ä¼˜åŒ–å™¨å‚æ•°ï¼ˆå¦‚ {'lr': 0.001}ï¼‰
            checkpoint_dir: æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½•
            buffer_size_mb: ç¼“å†²åŒºå¤§å°ï¼ˆMBï¼‰
            use_pccheck: æ˜¯å¦ä½¿ç”¨çœŸå®çš„ PCCheck
            use_monitor: æ˜¯å¦ä½¿ç”¨ Chk_monitorï¼ˆåå°è¿›ç¨‹æ¨¡å¼ï¼Œæ›´é«˜æ•ˆï¼‰
            num_threads: PCCheck ä½¿ç”¨çš„çº¿ç¨‹æ•°
            max_async: æœ€å¤§å¹¶å‘æ£€æŸ¥ç‚¹æ•°é‡
            batch_size_mb: PCCheck æ‰¹æ¬¡å¤§å°ï¼ˆMBï¼‰
            ratio: CPU ç¼“å†²åŒºå¤§å°ç›¸å¯¹äºæ£€æŸ¥ç‚¹çš„å€æ•°
            c_lib_path: PCCheck C åº“è·¯å¾„
            is_distributed: æ˜¯å¦ä¸ºåˆ†å¸ƒå¼è®­ç»ƒ
            rank: å½“å‰è¿›ç¨‹çš„ rankï¼ˆåˆ†å¸ƒå¼è®­ç»ƒç”¨ï¼‰
            world_size: æ€»è¿›ç¨‹æ•°ï¼ˆåˆ†å¸ƒå¼è®­ç»ƒç”¨ï¼‰
            device: è®­ç»ƒè®¾å¤‡
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        """
        self.model = model.to(device)
        self.device = device
        self.verbose = verbose
        self.checkpoint_dir = checkpoint_dir
        
        # ğŸ”¥ æ–°å¢ï¼šæ‰¹é‡ä¿å­˜æ¨¡å¼ï¼ˆå½“ä½¿ç”¨ gpu_ar æ—¶ï¼Œè·³è¿‡ç»†ç²’åº¦è°ƒåº¦ï¼‰
        self.use_batch_checkpoint = use_pccheck  # å¦‚æœä½¿ç”¨ PCCheckï¼Œé»˜è®¤å¯ç”¨æ‰¹é‡æ¨¡å¼
        # å°†æ•´ä¸ª gpu_ar åˆ†ä¸ºå¤šå°‘ä¸ª chunk å¹¶è¡Œä¿å­˜ï¼ˆ1=ä¸åˆ†å—ï¼‰
        self.checkpoint_chunk_count = max(1, int(checkpoint_chunk_count))
        
        # åˆ›å»ºç›®å½•
        os.makedirs(checkpoint_dir, exist_ok=True)
        
        if verbose:
            print("="*100)
            print("åˆå§‹åŒ–åˆ†å±‚æ£€æŸ¥ç‚¹è®­ç»ƒç³»ç»Ÿ")
            print("="*100)
        
        # ====================================================================
        # é˜¶æ®µä¸€ï¼šæ„å»ºä¾èµ–å›¾
        # ====================================================================
        if verbose:
            print("\n[é˜¶æ®µ 1/5] æ„å»ºå‚æ•°æ›´æ–°ä¾èµ–å›¾...")
        self.dependency_builder = DependencyGraphBuilder(model, verbose=False)
        self.dependency_builder.build_dependency_graph()
        self.update_order = self.dependency_builder.get_update_order()
        self.layer_info = self.dependency_builder.layer_info
        
        if verbose:
            print(f"  âœ“ æ£€æµ‹åˆ° {len(self.update_order)} ä¸ªå¯è®­ç»ƒå±‚")
            print(f"  âœ“ æ€»å‚æ•°æ•°: {sum(info['param_count'] for info in self.layer_info.values()):,}")
        
        # ====================================================================
        # é˜¶æ®µäº”ï¼šåˆ›å»ºå…ƒæ•°æ®ç®¡ç†å™¨ï¼ˆéœ€è¦å…ˆåˆ›å»ºï¼Œåé¢è¦ç”¨ï¼‰
        # ====================================================================
        if verbose:
            print("\n[é˜¶æ®µ 5/5] åˆå§‹åŒ–å…ƒæ•°æ®ç®¡ç†å™¨...")
        metadata_dir = os.path.join(checkpoint_dir, "metadata")
        self.metadata_manager = CheckpointMetadataManager(
            metadata_dir=metadata_dir,
            verbose=False
        )
        if verbose:
            print(f"  âœ“ å…ƒæ•°æ®ç›®å½•: {metadata_dir}")
        
        # ====================================================================
        # é˜¶æ®µäºŒï¼šåˆ›å»ºåˆ†å±‚ä¼˜åŒ–å™¨ï¼ˆéœ€è¦å…ˆåˆ›å»ºï¼Œåé¢ initialize è¦ç”¨ï¼‰
        # ====================================================================
        if verbose:
            print("\n[é˜¶æ®µ 2/5] åˆ›å»ºåˆ†å±‚ä¼˜åŒ–å™¨...")
            
        base_optimizer = optimizer_class(model.parameters(), **optimizer_kwargs)
        
        # ğŸ”¥ æ‰¹é‡æ¨¡å¼ï¼šç¦ç”¨é€å±‚å›è°ƒï¼Œå‡å°‘å¼€é”€
        enable_callback = not self.use_batch_checkpoint
        
        self.optimizer = LayerwiseOptimizer(
            optimizer=base_optimizer,
            model=model,
            update_order=self.update_order,
            layer_info=self.layer_info,
            callback=self._optimizer_callback if enable_callback else None,  # ğŸ”¥ æ‰¹é‡æ¨¡å¼ä¸‹ä¸è®¾ç½®å›è°ƒ
            enable_timing=enable_callback,  # æ‰¹é‡æ¨¡å¼ä¸‹ä¸éœ€è¦è®¡æ—¶
            verbose=False
        )
        
        if verbose and self.use_batch_checkpoint:
            print(f"  âœ“ ä½¿ç”¨æ‰¹é‡ä¿å­˜æ¨¡å¼ï¼ˆè·³è¿‡é€å±‚å›è°ƒï¼‰")

        gpu_ar = None
        total_size = 0
        
        if use_pccheck and torch.cuda.is_available():
            if verbose:
                print("\n[PCCheck] è®¡ç®—æ¨¡å‹å’Œä¼˜åŒ–å™¨çš„æ€»å¤§å°...")
            
            try:
                # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨ do_opt_step=True æ¥æ­£ç¡®åˆå§‹åŒ–ä¼˜åŒ–å™¨çŠ¶æ€
                # è¿™ç¡®ä¿ gpu_ar åŒ…å«è¶³å¤Ÿçš„ç©ºé—´ç”¨äºï¼šæ¨¡å‹å‚æ•° + ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆ+ æ¢¯åº¦ï¼‰
                print(f"initialize start (do_opt_step=True for correct buffer allocation)")
                gpu_ar, total_size = initialize(model, [base_optimizer], do_opt_step=True)
                
                if verbose:
                    print(f"   - æ€»å¤§å°: {total_size/1e6:.2f}M å‚æ•°")
                    print(f"   - Threads: {num_threads}, Max async: {max_async}")
                
                # ğŸ”¥ è°ƒè¯•ï¼šéªŒè¯ç¼“å†²åŒºå¤§å°æ˜¯å¦è¶³å¤Ÿ
                model_params_size = sum(p.numel() for p in model.parameters())
                grad_size = sum(p.grad.numel() for p in model.parameters() if p.grad is not None)
                opt_state_size = total_size - model_params_size
                
                if verbose:
                    print(f"   - æ¨¡å‹å‚æ•°: {model_params_size/1e6:.2f}M")
                    print(f"   - æ¢¯åº¦ç©ºé—´: {grad_size/1e6:.2f}M")
                    print(f"   - ä¼˜åŒ–å™¨çŠ¶æ€: {opt_state_size/1e6:.2f}M")
                    print(f"   - GPU ç¼“å†²åŒº: {len(gpu_ar)/1e6:.2f}M (åº” >= å‚æ•°+æ¢¯åº¦)")
                
                # æ–­è¨€ï¼šç¡®ä¿ç¼“å†²åŒºè¶³å¤Ÿå¤§
                required_size = model_params_size + grad_size
                assert len(gpu_ar) >= required_size, \
                    f"GPU ç¼“å†²åŒºä¸è¶³ï¼éœ€è¦ {required_size/1e6:.2f}Mï¼Œå®é™… {len(gpu_ar)/1e6:.2f}M"
                
                # è®¾ç½®å­˜å‚¨ï¼ˆå°†æ¨¡å‹å‚æ•°å’Œæ¢¯åº¦æ˜ å°„åˆ° gpu_arï¼‰
                set_storage(model, [base_optimizer], gpu_ar)
                
                if verbose:
                    print(f"   âœ“ set_storage å®Œæˆï¼Œå‚æ•°å·²é‡å®šå‘åˆ°ç»Ÿä¸€ç¼“å†²åŒº")
                    # éªŒè¯å‚æ•°ç¡®å®è¢«é‡å®šå‘
                    for name, p in list(model.named_parameters())[:2]:
                        print(f"     {name}: data_ptr={p.data_ptr()}, device={p.device}")
                
                print(f"initialize end")
                
            except Exception as e:
                print(f"  âš ï¸ gpu_ar åˆ†é…å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                gpu_ar = None
                total_size = 0
                use_pccheck = False  # ç¦ç”¨ PCCheck
        
        # ====================================================================
        # é˜¶æ®µå››ï¼šåˆ›å»º PCCheck é€‚é…å™¨ï¼ˆä¼ å…¥ gpu_arï¼‰
        # ====================================================================
        if verbose:
            print("\n[é˜¶æ®µ 4/5] åˆå§‹åŒ– PCCheck é€‚é…å™¨...")
        checkpoint_file = os.path.join(checkpoint_dir, "checkpoint.chk")
        self.pccheck_adapter = PCCheckAdapter(
            c_lib_path=c_lib_path or "./libtest_ssd.so",
            checkpoint_file=checkpoint_file,
            num_threads=num_threads,
            max_async=max_async,
            batch_size_mb=batch_size_mb,
            ratio=ratio,
            use_pccheck=use_pccheck,
            use_monitor=use_monitor,
            metadata_file=os.path.join(metadata_dir, "adapter_metadata.json"),
            is_distributed=is_distributed,
            rank=rank,
            world_size=world_size,
            gpu_ar=gpu_ar,  # ğŸ”¥ ä¼ å…¥åŸ PCCheck æ„é€ çš„ gpu_ar
            total_size=total_size,  # ğŸ”¥ ä¼ å…¥æ€»å¤§å°
            verbose=False
        )
        
        # å¦‚æœæ²¡æœ‰ä½¿ç”¨ gpu_arï¼Œåˆ™åˆ†é… staging buffer
        if gpu_ar is None:
            self.pccheck_adapter.allocate_staging_buffer(size_mb=buffer_size_mb * 2)
            
        if verbose:
            print(f"  âœ“ æ£€æŸ¥ç‚¹æ–‡ä»¶: {checkpoint_file}")
            mode_str = "PCCheck Monitor" if (use_pccheck and use_monitor) else ("PCCheck" if use_pccheck else "Mock")
            print(f"  âœ“ æ¨¡å¼: {mode_str}")
            if use_pccheck:
                print(f"  âœ“ çº¿ç¨‹æ•°: {num_threads}")
                print(f"  âœ“ æœ€å¤§å¼‚æ­¥æ•°: {max_async}")
                print(f"  âœ“ æ‰¹æ¬¡å¤§å°: {batch_size_mb} MB")
                if use_monitor:
                    print(f"  âš¡ Monitor æ¨¡å¼ï¼šå¼‚æ­¥ä¿å­˜å·²å¯ç”¨ï¼ˆé¢„æœŸ ~2-5ms å¼€é”€ï¼‰")
                else:
                    print(f"  âš ï¸  ç›´æ¥æ¨¡å¼ï¼šåŒæ­¥ä¿å­˜ï¼ˆé¢„æœŸ ~273ms å¼€é”€ï¼‰")
                if gpu_ar is not None:
                    print(f"  âœ“ ä½¿ç”¨åŸ PCCheck gpu_ar: {total_size * 4 / (1024**2):.2f} MB")
        
        # ====================================================================
        # é˜¶æ®µä¸‰ï¼šåˆ›å»ºè°ƒåº¦å™¨
        # ====================================================================
        if verbose:
            print("\n[é˜¶æ®µ 3/5] åˆå§‹åŒ–æ£€æŸ¥ç‚¹è°ƒåº¦å™¨...")
        self.scheduler = LayerwiseCheckpointScheduler(
            save_callback=self._save_callback,
            buffer_size_mb=buffer_size_mb,
            buffer_timeout_ms=100.0,
            enable_async=True,
            metadata_dir=metadata_dir,
            verbose=False
        )
        if verbose:
            print(f"  âœ“ ç¼“å†²åŒºå¤§å°: {buffer_size_mb} MB")
            print(f"  âœ“ å¼‚æ­¥æ¨¡å¼: å·²å¯ç”¨")
        
        # ====================================================================
        # ä¼˜åŒ–å™¨é…ç½®
        # ====================================================================
        # ğŸ”¥ æ–°å¢ï¼šé»˜è®¤ä½¿ç”¨æ‰‹åŠ¨æ¨¡å¼ï¼ˆåªåœ¨éœ€è¦æ—¶è§¦å‘å›è°ƒï¼ŒèŠ‚çœå¼€é”€ï¼‰
        self.optimizer.set_checkpoint_mode('manual')
        
        if verbose:
            print(f"\n[ä¼˜åŒ–å™¨é…ç½®]")
            print(f"  âœ“ ä¼˜åŒ–å™¨: {optimizer_class.__name__}")
            print(f"  âœ“ å‚æ•°: {optimizer_kwargs}")
            print(f"  âœ“ æ£€æŸ¥ç‚¹æ¨¡å¼: manual (ä»…åœ¨éœ€è¦æ—¶è§¦å‘å›è°ƒ)")
        
        # è®­ç»ƒç»Ÿè®¡
        self.current_training_step = 0
        self.current_checkpoint_id = None
        
        if verbose:
            print("\n" + "="*100)
            print("âœ“ æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆï¼")
            print("="*100)
    
    def _optimizer_callback(self, layer_name: str, step: int, layer_params: dict):
        """
        ä» LayerwiseOptimizer æ¥æ”¶å›è°ƒï¼ˆé˜¶æ®µäºŒ â†’ é˜¶æ®µä¸‰ï¼‰
        """
        # å°†ä»»åŠ¡ä¼ é€’ç»™è°ƒåº¦å™¨
        self.scheduler.schedule_save(layer_name, step, layer_params)
        
        # åŒæ—¶è®°å½•åˆ°å…ƒæ•°æ®ç®¡ç†å™¨
        if self.current_checkpoint_id:
            # è®¡ç®—åç§»é‡ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…éœ€è¦ç´¯ç§¯ï¼‰
            offset = self.pccheck_adapter.current_file_offset
            size_bytes = sum(p.numel() * p.element_size() for p in layer_params['parameters'])
            
            try:
                self.metadata_manager.add_layer(
                    checkpoint_id=self.current_checkpoint_id,
                    layer_name=layer_name,
                    offset=offset,
                    size_bytes=size_bytes,
                    param_count=layer_params['param_count'],
                    shapes=layer_params['shapes'],
                    dtypes=[str(dt) for dt in layer_params['dtypes']]
                )
            except KeyError:
                # å¦‚æœæ£€æŸ¥ç‚¹æœªæ³¨å†Œï¼Œå…ˆæ³¨å†Œ
                self.metadata_manager.register_checkpoint(
                    checkpoint_id=self.current_checkpoint_id,
                    training_step=step,
                    checkpoint_file=self.pccheck_adapter.checkpoint_file
                )
                # å†æ¬¡å°è¯•æ·»åŠ å±‚
                self.metadata_manager.add_layer(
                    checkpoint_id=self.current_checkpoint_id,
                    layer_name=layer_name,
                    offset=offset,
                    size_bytes=size_bytes,
                    param_count=layer_params['param_count'],
                    shapes=layer_params['shapes'],
                    dtypes=[str(dt) for dt in layer_params['dtypes']]
                )
    
    def _save_callback(self, tasks):
        """
        ä»è°ƒåº¦å™¨æ¥æ”¶æ‰¹é‡ä¿å­˜ä»»åŠ¡ï¼ˆé˜¶æ®µä¸‰ â†’ é˜¶æ®µå››ï¼‰
        """
        # å°†ä»»åŠ¡ä¼ é€’ç»™ PCCheck é€‚é…å™¨
        self.pccheck_adapter.save_layers_batch(tasks)
    
    def train_step(self, inputs, labels, criterion, enable_checkpoint: bool = False):
        """
        æ‰§è¡Œä¸€æ­¥è®­ç»ƒ
        
        Args:
            inputs: è¾“å…¥æ•°æ®
            labels: æ ‡ç­¾
            criterion: æŸå¤±å‡½æ•°
            enable_checkpoint: ğŸ”¥ æ–°å¢ï¼šæ˜¯å¦å¯ç”¨æ£€æŸ¥ç‚¹ä¿å­˜ï¼ˆé»˜è®¤Falseï¼Œä¸è§¦å‘å›è°ƒï¼‰
        
        Returns:
            loss: æŸå¤±å€¼ (scalar)
        """
        self.current_training_step += 1
        self.current_checkpoint_id = f"step_{self.current_training_step}"
        
        # ğŸ”¥ è®¾ç½®æ£€æŸ¥ç‚¹æ ‡å¿—ï¼ˆæ§åˆ¶ä¼˜åŒ–å™¨æ˜¯å¦è§¦å‘å›è°ƒï¼‰
        if not self.use_batch_checkpoint:
            # ç»†ç²’åº¦æ¨¡å¼ï¼šå¯ç”¨å›è°ƒ
            self.optimizer.enable_checkpointing(enable_checkpoint)
        
        # å‰å‘ä¼ æ’­
        outputs = self.model(inputs)
        
        # å¤„ç†ä¸åŒçš„è¾“å‡ºæ ¼å¼
        # å¦‚æœæ˜¯ Transformer è¾“å‡º (batch, seq_len, vocab_size)ï¼Œéœ€è¦é‡å¡‘
        if len(outputs.shape) == 3:
            loss = criterion(outputs.view(-1, outputs.size(-1)), labels.view(-1))
        else:
            loss = criterion(outputs, labels)
        
        # åå‘ä¼ æ’­
        self.optimizer.zero_grad()
        loss.backward()
        
        # ğŸ”¥ æ›´æ–°å‚æ•°
        self.optimizer.step()
        
        # ğŸ”¥ æ‰¹é‡æ¨¡å¼ï¼šåœ¨ step å®Œæˆåä¸€æ¬¡æ€§ä¿å­˜
        if enable_checkpoint and self.use_batch_checkpoint:
            self._save_checkpoint_batch()
        
        return loss.item()
    
    def _save_checkpoint_batch(self):
        """
        æ‰¹é‡ä¿å­˜æ¨¡å¼ï¼šç›´æ¥ä¿å­˜æ•´ä¸ª gpu_ar
        
        é€‚ç”¨äºï¼šå‚æ•°é€šè¿‡ set_storage åœ¨ gpu_ar ä¸­
        ä¼˜åŠ¿ï¼š
        - 0 æ¬¡å›è°ƒå¼€é”€ï¼ˆvs 148 æ¬¡ï¼‰
        - 1 æ¬¡ I/Oï¼ˆvs 5-7 æ¬¡ï¼‰
        - å¤§å—å†™å…¥ï¼ˆ500MB vs 100MBï¼‰ï¼Œé¥±å’Œå¸¦å®½
        """
        if self.pccheck_adapter.gpu_ar is None:
            if self.verbose:
                print("[Trainer] è­¦å‘Šï¼šæ‰¹é‡æ¨¡å¼ä½† gpu_ar ä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜")
            return
        
        # ç›´æ¥è°ƒç”¨é€‚é…å™¨çš„æ‰¹é‡ä¿å­˜æ¥å£
        if getattr(self, 'checkpoint_chunk_count', 1) > 1:
            # åˆ†å—å¹¶è¡Œä¿å­˜
            self.pccheck_adapter.save_entire_checkpoint_in_chunks(
                checkpoint_id=self.current_checkpoint_id,
                training_step=self.current_training_step,
                chunk_count=self.checkpoint_chunk_count
            )
        else:
            self.pccheck_adapter.save_entire_checkpoint(
                checkpoint_id=self.current_checkpoint_id,
                training_step=self.current_training_step
            )
    
    def finalize_checkpoint(self):
        """å®Œæˆå½“å‰æ£€æŸ¥ç‚¹çš„ä¿å­˜"""
        if self.current_checkpoint_id:
            # ğŸ”¥ æ‰¹é‡æ¨¡å¼ï¼šä¿å­˜å·²åœ¨ train_step ä¸­å®Œæˆï¼Œè¿™é‡Œåªéœ€ä¿å­˜å…ƒæ•°æ®
            if not self.use_batch_checkpoint:
                # ç»†ç²’åº¦æ¨¡å¼ï¼šå¼ºåˆ¶åˆ·æ–°è°ƒåº¦å™¨
                self.scheduler.force_flush()
            
            # ä¿å­˜å…ƒæ•°æ®
            self.metadata_manager.save_metadata(self.current_checkpoint_id)
            
            # éªŒè¯æ£€æŸ¥ç‚¹
            if not self.use_batch_checkpoint:
                total_layers = len(self.update_order)
                self.scheduler.finalize_checkpoint(self.current_training_step, total_layers)
    
    def shutdown(self):
        """å…³é—­è®­ç»ƒç³»ç»Ÿ"""
        if self.verbose:
            print("\n" + "="*100)
            print("å…³é—­åˆ†å±‚æ£€æŸ¥ç‚¹è®­ç»ƒç³»ç»Ÿ")
            print("="*100)
        
        # å…³é—­å„ä¸ªç»„ä»¶
        if self.verbose:
            print("\n[1/4] å…³é—­è°ƒåº¦å™¨ï¼ˆå¹¶å®Œæˆæœ€åçš„æ£€æŸ¥ç‚¹ï¼‰...")
        # å¼ºåˆ¶åˆ·æ–°è°ƒåº¦å™¨ä»¥å¤„ç†æ‰€æœ‰å‰©ä½™ä»»åŠ¡
        self.scheduler.force_flush()
        # ä¿å­˜æœ€åçš„å…ƒæ•°æ®
        if self.current_checkpoint_id:
            self.metadata_manager.save_metadata(self.current_checkpoint_id)
        # ç°åœ¨å…³é—­è°ƒåº¦å™¨
        self.scheduler.shutdown()
        
        if self.verbose:
            print("\n[2/4] å…³é—­ PCCheck é€‚é…å™¨...")
        self.pccheck_adapter.shutdown()
        
        if self.verbose:
            print("\n[3/4] ä¿å­˜æ‰€æœ‰å…ƒæ•°æ®...")
        self.metadata_manager.save_metadata()
        
        if self.verbose:
            print("\n[4/4] æ‰“å°ä¼˜åŒ–å™¨ç»Ÿè®¡...")
            self.optimizer.print_timing_stats()
        
        if self.verbose:
            print("\n" + "="*100)
            print("âœ“ ç³»ç»Ÿå·²å…³é—­")
            print("="*100)


# ============================================================================
# ä¸»å‡½æ•°ï¼šå®Œæ•´çš„è®­ç»ƒå’Œæ¢å¤æ¼”ç¤º
# ============================================================================

def main():
    """å®Œæ•´æ¼”ç¤ºï¼šè®­ç»ƒ + ä¿å­˜ + æ¢å¤"""
    
    print("\n" + "="*100)
    print("åˆ†å±‚æ£€æŸ¥ç‚¹ç³»ç»Ÿ - å®Œæ•´æ¼”ç¤º")
    print("="*100)
    
    # ========================================================================
    # Part 1: è®­ç»ƒå¹¶ä¿å­˜æ£€æŸ¥ç‚¹
    # ========================================================================
    print("\n" + "="*100)
    print("Part 1: è®­ç»ƒå¹¶ä¿å­˜åˆ†å±‚æ£€æŸ¥ç‚¹")
    print("="*100)
    
    # åˆ›å»ºæ¨¡å‹
    model = SimpleCNN(num_classes=10)
    
    # åˆ›å»ºè®­ç»ƒæ•°æ®
    num_samples = 100
    X_train = torch.randn(num_samples, 3, 32, 32)
    y_train = torch.randint(0, 10, (num_samples,))
    train_dataset = TensorDataset(X_train, y_train)
    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = LayerwiseCheckpointTrainer(
        model=model,
        optimizer_class=torch.optim.Adam,
        optimizer_kwargs={'lr': 0.001},
        checkpoint_dir="./demo_checkpoints",
        buffer_size_mb=10.0,
        use_pccheck=True,          # å¯ç”¨ PCCheck
        use_monitor=True,         # æ˜¯å¦ä½¿ç”¨ Monitor æ¨¡å¼ï¼ˆTrue æ›´é«˜æ•ˆï¼‰
        num_threads=8,             # 8 ä¸ªå¹¶è¡Œçº¿ç¨‹
        max_async=4,               # æœ€å¤š 4 ä¸ªå¹¶å‘æ£€æŸ¥ç‚¹
        batch_size_mb=100.0,       # æ¯æ‰¹ 100MB
        ratio=2.0,                 # CPU ç¼“å†²åŒºæ˜¯æ£€æŸ¥ç‚¹çš„ 2 å€
        device='cuda',             # ä½¿ç”¨ GPU
        c_lib_path="/home/linzhicheng/code/pccheck/checkpoint_eval/pccheck/libtest_ssd.so",
        verbose=True
    )
    
    # æŸå¤±å‡½æ•°
    criterion = nn.CrossEntropyLoss()
    
    # è®­ç»ƒå¾ªç¯
    print("\n" + "-"*100)
    print("å¼€å§‹è®­ç»ƒ...")
    print("-"*100)
    
    num_epochs = 2
    for epoch in range(num_epochs):
        print(f"\nEpoch {epoch + 1}/{num_epochs}")
        epoch_loss = 0.0
        correct = 0
        total = 0
        
        for batch_idx, (inputs, labels) in enumerate(train_loader):
            # å°†æ•°æ®ç§»åˆ°è®¾å¤‡
            inputs = inputs.to(trainer.device)
            labels = labels.to(trainer.device)
            
            # è®­ç»ƒä¸€æ­¥ï¼ˆä¼šè‡ªåŠ¨ä¿å­˜æ£€æŸ¥ç‚¹ï¼‰
            loss, outputs = trainer.train_step(inputs, labels, criterion)
            
            # è®¡ç®—å‡†ç¡®ç‡
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
            epoch_loss += loss
            
            if (batch_idx + 1) % 5 == 0:
                avg_loss = epoch_loss / (batch_idx + 1)
                acc = 100.0 * correct / total
                print(f"  Batch [{batch_idx + 1:2d}/{len(train_loader):2d}] | "
                      f"Loss: {avg_loss:.4f} | Acc: {acc:.2f}%")
        
        # Epoch ç»“æŸ
        avg_loss = epoch_loss / len(train_loader)
        acc = 100.0 * correct / total
        print(f"  â†’ Epoch {epoch + 1} å®Œæˆ | Loss: {avg_loss:.4f} | Acc: {acc:.2f}%")
    
    # å…³é—­è®­ç»ƒå™¨
    trainer.shutdown()
    
    # ========================================================================
    # Part 2: ä»æ£€æŸ¥ç‚¹æ¢å¤æ¨¡å‹
    # ========================================================================
    print("\n" + "="*100)
    print("Part 2: ä»æ£€æŸ¥ç‚¹æ¢å¤æ¨¡å‹")
    print("="*100)
    
    # åˆ›å»ºæ–°æ¨¡å‹ï¼ˆéšæœºåˆå§‹åŒ–ï¼‰
    new_model = SimpleCNN(num_classes=10)
    print("\nåˆ›å»ºæ–°æ¨¡å‹ï¼ˆéšæœºåˆå§‹åŒ–ï¼‰")
    
    # åˆ›å»ºæ¢å¤å™¨
    recovery = ModelRecovery(
        metadata_manager=trainer.metadata_manager,
        verbose=True
    )
    
    # åˆ—å‡ºå¯ç”¨çš„æ£€æŸ¥ç‚¹
    print("\n" + "-"*100)
    print("å¯ç”¨çš„æ£€æŸ¥ç‚¹:")
    available_checkpoints = recovery.list_available_checkpoints()
    for chk_id, step in available_checkpoints:
        info = recovery.get_checkpoint_info(chk_id)
        if info:
            print(f"\n  {chk_id}:")
            print(f"    - è®­ç»ƒæ­¥æ•°: {info['training_step']}")
            print(f"    - å±‚æ•°: {info['total_layers']}")
            print(f"    - å¤§å°: {info['total_size_gb']:.4f} GB")
            print(f"    - åˆ›å»ºæ—¶é—´: {info['created_at']}")
    
    # æ¢å¤æœ€æ–°çš„æ£€æŸ¥ç‚¹
    if available_checkpoints:
        latest_checkpoint = available_checkpoints[-1][0]
        print(f"\n" + "-"*100)
        print(f"æ¢å¤æ£€æŸ¥ç‚¹: {latest_checkpoint}")
        print("-"*100)
        
        try:
            stats = recovery.load_checkpoint(
                model=new_model,
                checkpoint_id=latest_checkpoint,
                device='cpu',
                strict=False  # å®½æ¾æ¨¡å¼ï¼Œå…è®¸éƒ¨åˆ†æ¢å¤
            )
            
            print(f"\næ¢å¤ç»Ÿè®¡:")
            print(f"  - æ€»å±‚æ•°: {stats['total_layers']}")
            print(f"  - å·²åŠ è½½: {stats['loaded_layers']}")
            print(f"  - ç¼ºå¤±å±‚: {len(stats['missing_layers'])}")
            print(f"  - é¢å¤–å±‚: {len(stats['unexpected_layers'])}")
            
            if stats['missing_layers']:
                print(f"  - ç¼ºå¤±çš„å±‚: {stats['missing_layers'][:5]}...")
            
        except Exception as e:
            print(f"\næ¢å¤å¤±è´¥: {e}")
            print("æ³¨æ„ï¼šè¿™å¯èƒ½æ˜¯å› ä¸ºå…ƒæ•°æ®ä¸å®é™…æ•°æ®æ–‡ä»¶ä¸å®Œå…¨åŒ¹é…")
            print("åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œéœ€è¦æ›´å®Œå–„çš„é”™è¯¯å¤„ç†")
    

if __name__ == "__main__":
    main()
