import torch


def set_storage(model, optimizer_list, gpu_ar):
    """
    å°†æ¨¡å‹å‚æ•°ã€æ¢¯åº¦å’Œä¼˜åŒ–å™¨çŠ¶æ€æ˜ å°„åˆ° gpu_ar çš„è¿ç»­å†…å­˜åŒºåŸŸ
    
    ğŸ”¥ Phase 1 æ”¹è¿›ï¼šæ”¯æŒå®Œæ•´çš„ä¼˜åŒ–å™¨çŠ¶æ€æ˜ å°„
    
    å†…å­˜å¸ƒå±€ï¼ˆ4 Ã— model_size for Adamï¼‰ï¼š
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ [0, N)         : Model Parameters                           â”‚
    â”‚ [N, 2N)        : Gradients                                  â”‚
    â”‚ [2N, 3N)       : exp_avg (momentum for Adam)                â”‚
    â”‚ [3N, 4N)       : exp_avg_sq (adaptive LR for Adam)          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    Args:
        model: PyTorch æ¨¡å‹
        optimizer_list: ä¼˜åŒ–å™¨åˆ—è¡¨ï¼ˆé€šå¸¸åŒ…å«ä¸€ä¸ª Adam ä¼˜åŒ–å™¨ï¼‰
        gpu_ar: é¢„åˆ†é…çš„ CUDA tensorï¼Œå¤§å°ä¸º 4 Ã— model_size
    """
    start_idx = 0
    model_size = 0
    
    # ==================== Region 1: Model Parameters ====================
    for name, ref in model.named_parameters():
        end_idx = start_idx + ref.numel()
        my_ar = gpu_ar[start_idx:end_idx]
        prev_shape = ref.size()
        with torch.no_grad():
            temp = ref.clone()
            ref.set_(my_ar, 0, tuple(prev_shape))
            ref.copy_(temp)
        start_idx += ref.numel()
        model_size += ref.numel()

    # ==================== Region 2: Gradients ====================
    for optimizer in optimizer_list:
        for group in optimizer.param_groups:
            for p in group['params']:
                if p.grad is not None:
                    end_idx = start_idx + p.grad.numel()
                    my_ar = gpu_ar[start_idx:end_idx]
                    prev_shape = p.grad.size()
                    p.grad.set_(my_ar, 0, tuple(prev_shape))
                    start_idx += p.grad.numel()
    
    # ==================== Region 3 & 4: Optimizer States (exp_avg, exp_avg_sq) ====================
    # ğŸ”¥ Phase 1 æ–°å¢ï¼šæ˜ å°„ä¼˜åŒ–å™¨çŠ¶æ€åˆ° gpu_ar
    for optimizer in optimizer_list:
        # æŒ‰å‚æ•°é¡ºåºæ˜ å°„ä¼˜åŒ–å™¨çŠ¶æ€
        for group in optimizer.param_groups:
            for p in group['params']:
                # ğŸ”¥ æ³¨æ„ï¼šoptimizer.state çš„é”®æ˜¯ tensor å¯¹è±¡æœ¬èº«ï¼Œä¸æ˜¯ id(p)
                if p in optimizer.state:
                    state = optimizer.state[p]
                    
                    # æ˜ å°„ exp_avgï¼ˆmomentumï¼‰
                    if 'exp_avg' in state:
                        exp_avg = state['exp_avg']
                        end_idx = start_idx + exp_avg.numel()
                        my_ar = gpu_ar[start_idx:end_idx]
                        prev_shape = exp_avg.size()
                        with torch.no_grad():
                            temp = exp_avg.clone()
                            exp_avg.set_(my_ar, 0, tuple(prev_shape))
                            exp_avg.copy_(temp)
                        start_idx += exp_avg.numel()
                    
                    # æ˜ å°„ exp_avg_sqï¼ˆadaptive learning rateï¼‰
                    if 'exp_avg_sq' in state:
                        exp_avg_sq = state['exp_avg_sq']
                        end_idx = start_idx + exp_avg_sq.numel()
                        my_ar = gpu_ar[start_idx:end_idx]
                        prev_shape = exp_avg_sq.size()
                        with torch.no_grad():
                            temp = exp_avg_sq.clone()
                            exp_avg_sq.set_(my_ar, 0, tuple(prev_shape))
                            exp_avg_sq.copy_(temp)
                        start_idx += exp_avg_sq.numel()
    
    print(f"âœ… [set_storage] gpu_ar å†…å­˜æ˜ å°„å®Œæˆ:")
    print(f"   - Model params: [0, {model_size})")
    print(f"   - Gradients: [{model_size}, {model_size*2})")
    print(f"   - exp_avg: [{model_size*2}, {model_size*3})")
    print(f"   - exp_avg_sq: [{model_size*3}, {model_size*4})")
    print(f"   - Total used: {start_idx} / {gpu_ar.numel()} ({100*start_idx/gpu_ar.numel():.1f}%)")
    
    return model_size  # ğŸ”¥ è¿”å› model_size ç”¨äºåç»­è®¡ç®—åç§»


def initialize(model, optimizer_list, do_opt_step=True):
    if isinstance(model, dict):
        model_state = model
    else:
        model_state = model.state_dict()

    # initialize optimizer for realistic setups
    for optimizer in optimizer_list:
        opt_state = optimizer.state_dict()
        if len(opt_state['state']) == 0:
            for group in optimizer.param_groups:
                for p in group['params']:
                    p.grad = p.data.new(p.size())
        if do_opt_step:
            optimizer.step()

    # ğŸ”¥ Phase 1: è®¡ç®— model_sizeï¼ˆä»…å‚æ•°ï¼‰
    model_size = 0
    for name, ref in model_state.items():
        if (torch.is_tensor(ref)):
            model_size += ref.numel()
        elif (type(ref) == int or type(ref) == float):
            model_size += 1

    # ğŸ”¥ Phase 1: è®¡ç®— opt_sizeï¼ˆä»… tensor çŠ¶æ€ï¼Œä¸åŒ…æ‹¬æ ‡é‡ step ç­‰ï¼‰
    # Adam ä¼˜åŒ–å™¨æœ‰ï¼šexp_avg, exp_avg_sqï¼ˆæ¯ä¸ªå‚æ•°å„ä¸€ä»½ï¼‰
    # å¸ƒå±€ï¼š[params | grads | exp_avg | exp_avg_sq] = 4 Ã— model_size
    opt_size = 0
    for optimizer in optimizer_list:
        opt_state = optimizer.state_dict()
        for name, _ in opt_state['state'].items():
            for k, ref in opt_state['state'][name].items():
                # ğŸ”¥ åªè®¡ç®— tensorï¼ˆexp_avg, exp_avg_sqï¼‰ï¼Œè·³è¿‡æ ‡é‡ï¼ˆstepï¼‰
                if torch.is_tensor(ref):
                    opt_size += ref.numel()
                # æ³¨æ„ï¼šä¸å†è®¡ç®— int/floatï¼Œå› ä¸ºå®ƒä»¬ä¸éœ€è¦æ˜ å°„åˆ° gpu_ar
    
    # ğŸ”¥ Phase 1: total_size = params + grads + optimizer_tensors
    # å¯¹äº Adamï¼š= N + N + 2N = 4N
    total_size = model_size + model_size + opt_size  # params + grads + opt_tensors
    gpu_ar = torch.zeros(total_size).cuda()

    return gpu_ar, total_size


def get_total_size(model, optimizer_list):
    model_state = model.state_dict()
    model_size = 0
    for name, ref in model_state.items():
        if (torch.is_tensor(ref)):
            model_size += ref.numel()
        elif (type(ref) == int or type(ref) == float):
            model_size += 1

    opt_size = 0
    for optimizer in optimizer_list:
        opt_state = optimizer.state_dict()
        for name, _ in opt_state['state'].items():
            for k, ref in opt_state['state'][name].items():
                # print(k, ref.dtype)
                if (torch.is_tensor(ref)):
                    opt_size += ref.numel()
                elif (type(ref) == int or type(ref) == float):
                    opt_size += 1

    return model_size + opt_size
