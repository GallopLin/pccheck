#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PCCheck æ”¹è¿›æ•ˆæœå¯¹æ¯”å®éªŒ
Benchmark Comparison: Traditional vs Original vs Layerwise vs Multistream Checkpoint

å¯¹æ¯”å››ç§æ£€æŸ¥ç‚¹æ–¹æ³•ï¼š
1. ä¼ ç»Ÿ PyTorch æ£€æŸ¥ç‚¹ (torch.save)
2. åŸå§‹ PCCheck
3. æ”¹è¿›çš„åˆ†å±‚ PCCheck (Layerwise)
4. å¤šæµå¹¶è¡Œ PCCheck (Multistream)

æµ‹é‡æŒ‡æ ‡ï¼š
- æ£€æŸ¥ç‚¹ä¿å­˜æ—¶é—´
- è®­ç»ƒååé‡ (samples/sec)
- å†…å­˜å³°å€¼
- æ€»è®­ç»ƒæ—¶é—´
- I/O å¼€é”€å æ¯”
"""

import os
import sys
import time
import json
import argparse
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
from typing import Dict, List, Tuple
import psutil
try:
    import GPUtil
    GPU_AVAILABLE = True
except ImportError:
    GPU_AVAILABLE = False
    print("[Warning] GPUtil not available, GPU memory monitoring disabled")
from datetime import datetime

# æ·»åŠ è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'pccheck'))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'pccheck', 'layerwise_checkpoint'))

try:
    from checkpoint_eval.pccheck.layerwise_checkpoint.complete_integration import LayerwiseCheckpointTrainer
except ImportError:
    print("[Warning] LayerwiseCheckpointTrainer not found, skipping layerwise benchmark")
    LayerwiseCheckpointTrainer = None

from checkpoint_eval.pccheck.chk_monitor import Chk_monitor
from checkpoint_eval.pccheck_utils import initialize, get_total_size, set_storage
from checkpoint_eval.pccheck.multistream_checkpoint import MultiStreamCheckpoint, build_param_layout


class BenchmarkMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self, name: str):
        self.name = name
        self.checkpoint_times = []
        self.training_step_times = []
        self.memory_usage = []
        self.gpu_memory_usage = []
        self.total_time = 0.0
        self.throughput = 0.0
        self.num_samples = 0
        # IOä¼ è¾“é€Ÿç‡ç›¸å…³
        self.io_throughputs = []  # GB/s
        self.io_save_times = []   # å®é™…ä¿å­˜æ—¶é—´ï¼ˆç§’ï¼‰
        self.data_size_gb = 0.0   # æ£€æŸ¥ç‚¹æ•°æ®å¤§å°ï¼ˆGBï¼‰
        
    def add_checkpoint_time(self, time_ms: float):
        self.checkpoint_times.append(time_ms)
    
    def add_step_time(self, time_ms: float):
        self.training_step_times.append(time_ms)
    
    def add_io_stats(self, save_time_sec: float, throughput_gbps: float):
        """è®°å½•IOä¼ è¾“ç»Ÿè®¡"""
        self.io_save_times.append(save_time_sec)
        self.io_throughputs.append(throughput_gbps)
    
    def record_memory(self):
        """è®°å½•å†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆåŒ…å«å­è¿›ç¨‹ï¼‰"""
        process = psutil.Process()
        total_memory = process.memory_info().rss
        
        # ç´¯åŠ æ‰€æœ‰å­è¿›ç¨‹çš„å†…å­˜
        try:
            for child in process.children(recursive=True):
                try:
                    total_memory += child.memory_info().rss
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    pass
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            pass
            
        self.memory_usage.append(total_memory / 1024**3)  # GB
        
        # GPU å†…å­˜
        if GPU_AVAILABLE:
            try:
                gpus = GPUtil.getGPUs()
                if gpus:
                    self.gpu_memory_usage.append(gpus[0].memoryUsed / 1024)  # GB
            except:
                pass
    
    def compute_statistics(self):
        """è®¡ç®—ç»Ÿè®¡æ•°æ®"""
        return {
            'name': self.name,
            'checkpoint': {
                'mean_ms': np.mean(self.checkpoint_times) if self.checkpoint_times else 0,
                'std_ms': np.std(self.checkpoint_times) if self.checkpoint_times else 0,
                'min_ms': np.min(self.checkpoint_times) if self.checkpoint_times else 0,
                'max_ms': np.max(self.checkpoint_times) if self.checkpoint_times else 0,
                'total_ms': np.sum(self.checkpoint_times) if self.checkpoint_times else 0,
                'count': len(self.checkpoint_times),
            },
            'training_step': {
                'mean_ms': np.mean(self.training_step_times) if self.training_step_times else 0,
                'std_ms': np.std(self.training_step_times) if self.training_step_times else 0,
            },
            'memory': {
                'peak_cpu_gb': max(self.memory_usage) if self.memory_usage else 0,
                'peak_gpu_gb': max(self.gpu_memory_usage) if self.gpu_memory_usage else 0,
                'mean_cpu_gb': np.mean(self.memory_usage) if self.memory_usage else 0,
            },
            'throughput': {
                'samples_per_sec': self.throughput,
                'total_samples': self.num_samples,
            },
            'io_performance': {
                'data_size_gb': self.data_size_gb,
                'mean_io_throughput_gbps': np.mean(self.io_throughputs) if self.io_throughputs else 0,
                'std_io_throughput_gbps': np.std(self.io_throughputs) if self.io_throughputs else 0,
                'min_io_throughput_gbps': np.min(self.io_throughputs) if self.io_throughputs else 0,
                'max_io_throughput_gbps': np.max(self.io_throughputs) if self.io_throughputs else 0,
                'mean_save_time_sec': np.mean(self.io_save_times) if self.io_save_times else 0,
                'count': len(self.io_throughputs),
            },
            'total_time_sec': self.total_time,
            'checkpoint_overhead_percent': (np.sum(self.checkpoint_times) / 1000 / self.total_time * 100) if self.total_time > 0 else 0,
        }
    
    def print_summary(self):
        """æ‰“å°æ‘˜è¦"""
        stats = self.compute_statistics()
        print(f"\n{'='*80}")
        print(f"ğŸ“Š {stats['name']} - æ€§èƒ½æ‘˜è¦")
        print(f"{'='*80}")
        print(f"â±ï¸  æ€»è®­ç»ƒæ—¶é—´: {stats['total_time_sec']:.2f} ç§’")
        print(f"ğŸš€ ååé‡: {stats['throughput']['samples_per_sec']:.2f} samples/sec")
        print(f"ğŸ’¾ æ£€æŸ¥ç‚¹ä¿å­˜:")
        # print(f"   - å¹³å‡æ—¶é—´: {stats['checkpoint']['mean_ms']:.2f} ms")
        # print(f"   - æ€»æ—¶é—´: {stats['checkpoint']['total_ms']/1000:.2f} ç§’")
        # print(f"   - å¼€é”€å æ¯”: {stats['checkpoint_overhead_percent']:.2f}%")
        print(f"   - ä¿å­˜æ¬¡æ•°: {stats['checkpoint']['count']}")
        print(f"ğŸ“ˆ è®­ç»ƒæ­¥:")
        print(f"   - å¹³å‡æ—¶é—´: {stats['training_step']['mean_ms']:.2f} ms")
        print(f"ğŸ’» å†…å­˜:")
        print(f"   - CPU å³°å€¼: {stats['memory']['peak_cpu_gb']:.2f} GB")
        if stats['memory']['peak_gpu_gb'] > 0:
            print(f"   - GPU å³°å€¼: {stats['memory']['peak_gpu_gb']:.2f} GB")
        print(f"ğŸ“Š IOæ€§èƒ½:")
        if stats['io_performance']['count'] > 0:
            print(f"   - æ•°æ®å¤§å°: {stats['io_performance']['data_size_gb']:.2f} GB")
            print(f"   - å¹³å‡ä¼ è¾“é€Ÿç‡: {stats['io_performance']['mean_io_throughput_gbps']:.2f} GB/s")
            print(f"   - ä¼ è¾“é€Ÿç‡èŒƒå›´: {stats['io_performance']['min_io_throughput_gbps']:.2f} - {stats['io_performance']['max_io_throughput_gbps']:.2f} GB/s")
            print(f"   - å¹³å‡å®é™…ä¿å­˜æ—¶é—´: {stats['io_performance']['mean_save_time_sec']:.2f} ç§’")
            print(f"   - IOç»Ÿè®¡æ¬¡æ•°: {stats['io_performance']['count']}")
        else:
            print(f"   - æš‚æ— IOç»Ÿè®¡æ•°æ®ï¼ˆå¼‚æ­¥ä¿å­˜ä¸­ï¼‰")
        print(f"{'='*80}\n")


class TestModel(nn.Module):
    """æµ‹è¯•æ¨¡å‹ - å¯é…ç½®å¤§å°çš„ Transformer-like æ¨¡å‹"""
    
    def __init__(self, vocab_size=10000, d_model=512, nhead=8, num_layers=6, dim_feedforward=2048):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, d_model)
        self.pos_encoder = nn.Embedding(512, d_model)
        
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=dim_feedforward,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        self.fc = nn.Linear(d_model, vocab_size)
        
    def forward(self, x):
        # x: (batch, seq_len)
        positions = torch.arange(x.size(1), device=x.device).unsqueeze(0)
        x = self.embedding(x) + self.pos_encoder(positions)
        x = self.transformer(x)
        x = self.fc(x)
        return x


def create_synthetic_dataset(num_samples=1000, seq_len=128, vocab_size=10000):
    """åˆ›å»ºåˆæˆæ•°æ®é›†"""
    print(f"ğŸ“¦ åˆ›å»ºåˆæˆæ•°æ®é›†: {num_samples} samples, seq_len={seq_len}")
    X = torch.randint(0, vocab_size, (num_samples, seq_len))
    y = torch.randint(0, vocab_size, (num_samples, seq_len))
    return TensorDataset(X, y)


def build_test_layout_from_model(model, optimizer, total_size):
    """ä»æ¨¡å‹å’Œä¼˜åŒ–å™¨æ„å»ºæµ‹è¯•ç”¨çš„å‚æ•°å¸ƒå±€"""
    # è·å–æ¨¡å‹å‚æ•°ä¿¡æ¯
    param_info = []
    current_offset = 0
    layer_id = 0
    
    for name, param in model.named_parameters():
        param_size = param.numel()
        param_info.append({
            'layer_id': layer_id,
            'name': name,
            'param_offset': current_offset,
            'param_size': param_size,
            'grad_offset': total_size + current_offset,
            'grad_size': param_size,
            'exp_avg_offset': total_size * 2 + current_offset,
            'exp_avg_size': param_size,
            'exp_avg_sq_offset': total_size * 3 + current_offset,
            'exp_avg_sq_size': param_size,
        })
        current_offset += param_size
        layer_id += 1
    
    return param_info


def benchmark_traditional_checkpoint(
    model: nn.Module,
    train_loader: DataLoader,
    criterion,
    optimizer,
    device: str,
    checkpoint_freq: int,
    checkpoint_dir: str,
    num_steps: int = 100
) -> BenchmarkMetrics:
    """æµ‹è¯•ä¼ ç»Ÿ PyTorch æ£€æŸ¥ç‚¹"""
    
    print(f"\n{'='*80}")
    print(f"ğŸ”µ å¼€å§‹æµ‹è¯•: ä¼ ç»Ÿ PyTorch æ£€æŸ¥ç‚¹")
    print(f"{'='*80}")
    
    metrics = BenchmarkMetrics("Traditional PyTorch Checkpoint")
    model.train()
    
    os.makedirs(checkpoint_dir, exist_ok=True)
    
    step = 0
    total_samples = 0
    start_time = time.time()
    
    data_iter = iter(train_loader)
    
    while step < num_steps:
        try:
            data, target = next(data_iter)
        except StopIteration:
            data_iter = iter(train_loader)
            data, target = next(data_iter)
        
        data, target = data.to(device), target.to(device)
        batch_size = data.size(0)
        
        # è®­ç»ƒæ­¥
        step_start = time.time()
        
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output.view(-1, output.size(-1)), target.view(-1))
        loss.backward()
        optimizer.step()
        
        step_time = (time.time() - step_start) * 1000
        metrics.add_step_time(step_time)
        
        total_samples += batch_size
        step += 1
        
        # æ£€æŸ¥ç‚¹ä¿å­˜
        if step % checkpoint_freq == 0:
            chk_start = time.time()
            
            checkpoint_path = os.path.join(checkpoint_dir, f"checkpoint_step_{step}.pth")
            torch.save({
                'step': step,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': loss.item(),
            }, checkpoint_path)
            
            chk_time = (time.time() - chk_start) * 1000
            metrics.add_checkpoint_time(chk_time)
            # å‡å°‘è¾“å‡ºé¢‘ç‡
            if step % (checkpoint_freq * 5) == 0:  # æ¯5æ¬¡æ£€æŸ¥ç‚¹è¾“å‡ºä¸€æ¬¡
                print(f"  âœ“ Step {step}: ä¿å­˜æ£€æŸ¥ç‚¹ ({chk_time:.2f} ms)")
        
        # è®°å½•å†…å­˜
        if step % 10 == 0:
            metrics.record_memory()
    
    total_time = time.time() - start_time
    metrics.total_time = total_time
    metrics.num_samples = total_samples
    metrics.throughput = total_samples / total_time
    
    return metrics


def benchmark_original_pccheck(
    model: nn.Module,
    train_loader: DataLoader,
    criterion,
    optimizer,
    device: str,
    checkpoint_freq: int,
    checkpoint_file: str,
    num_threads: int,
    max_async: int,
    num_steps: int = 100
) -> BenchmarkMetrics:
    """æµ‹è¯•åŸå§‹ PCCheck"""
    
    print(f"\n{'='*80}")
    print(f"ğŸŸ¢ å¼€å§‹æµ‹è¯•: åŸå§‹ PCCheck")
    print(f"{'='*80}")
    
    metrics = BenchmarkMetrics("Original PCCheck")
    model.train()
    
    # åˆå§‹åŒ– PCCheck Monitor
    print(f"ğŸ“ åˆå§‹åŒ– PCCheck Monitor:")
    
    # âœ… ä¿®å¤ï¼šä½¿ç”¨ do_opt_step=True æ¥åˆå§‹åŒ–ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆexp_avg, exp_avg_sqï¼‰
    # è¿™ç¡®ä¿ gpu_ar åŒ…å«å®Œæ•´çš„ 4 ä»½æ•°æ®ï¼šparam, grad, exp_avg, exp_avg_sq
    gpu_ar, total_size = initialize(model, [optimizer], do_opt_step=True)
    
    print(f"   - æ¨¡å‹å¤§å°: {total_size/1e6:.2f}M å‚æ•°")
    print(f"   - Threads: {num_threads}, Max async: {max_async}")
    
    # è®¾ç½®å­˜å‚¨
    set_storage(model, [optimizer], gpu_ar)
    torch.cuda.empty_cache()
    
    # åˆ›å»º Chk_monitor
    c_lib_path = "/home/linzhicheng/data/pccheck/checkpoint_eval/pccheck/libtest_ssd.so"
    gpu_copy = True if device == 'cuda' else False
    
    monitor = Chk_monitor(
        c_lib_path,
        total_size,
        num_threads,
        max_async,
        gpu_copy,
        gpu_ar=gpu_ar,
        bsize=total_size // 4,
        model=model.state_dict(),
        optimizer=optimizer.state_dict(),
        memory_saving=True,
        is_distributed=False,
        rank=0,
        world_size=1
    )
    
    step = 0
    total_samples = 0
    start_time = time.time()
    
    data_iter = iter(train_loader)
    
    while step < num_steps:
        try:
            data, target = next(data_iter)
        except StopIteration:
            data_iter = iter(train_loader)
            data, target = next(data_iter)
        
        data, target = data.to(device), target.to(device)
        batch_size = data.size(0)
        
        # è®­ç»ƒæ­¥
        step_start = time.time()
        
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output.view(-1, output.size(-1)), target.view(-1))
        loss.backward()
        optimizer.step()
        
        total_samples += batch_size
        step += 1
        
        # æ£€æŸ¥ç‚¹ä¿å­˜
        if step % checkpoint_freq == 0:
            chk_start = time.time()
            
            # æ›´æ–° checkpoint_dict ä¸­çš„çŠ¶æ€
            monitor.checkpoint_dict['model'] = model.state_dict()
            monitor.checkpoint_dict['optimizer'] = optimizer.state_dict()
            
            # ä½¿ç”¨ PCCheck Monitor ä¿å­˜
            monitor.save()
            
            chk_time = (time.time() - chk_start) * 1000
            metrics.add_checkpoint_time(chk_time)
            # å‡å°‘è¾“å‡ºé¢‘ç‡
            if step % (checkpoint_freq * 5) == 0:  # æ¯5æ¬¡æ£€æŸ¥ç‚¹è¾“å‡ºä¸€æ¬¡
                print(f"  âœ“ Step {step}: PCCheck ä¿å­˜ ({chk_time:.2f} ms)")
        
        # è®°å½•å†…å­˜
        if step % 10 == 0:
            metrics.record_memory()
            
        step_time = (time.time() - step_start) * 1000
        metrics.add_step_time(step_time)
    
    # å…³é—­ monitor
    monitor.kill_checkpoint()
    total_time = time.time() - start_time
    metrics.total_time = total_time
    metrics.num_samples = total_samples
    metrics.throughput = total_samples / total_time
    
    return metrics


def benchmark_layerwise_pccheck(
    model: nn.Module,
    train_loader: DataLoader,
    criterion,
    device: str,
    checkpoint_dir: str,
    num_threads: int,
    max_async: int,
    buffer_size_mb: float,
    batch_size_mb: float,
    use_monitor: bool,
    checkpoint_freq: int,
    num_steps: int = 100,
    use_chunked_async: bool = True,  # ğŸ”¥ æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨åˆ†å—å¼‚æ­¥ä¿å­˜ï¼ˆé›¶æ‹·è´ä¼˜åŒ–ï¼‰
    chunk_size_mb: float = 512.0,    # ğŸ”¥ æ–°å¢ï¼šå—å¤§å°ï¼ˆMBï¼‰
    async_workers: int = 4            # ğŸ”¥ æ–°å¢ï¼šå¼‚æ­¥ä¿å­˜çº¿ç¨‹æ•°
) -> BenchmarkMetrics:
    """æµ‹è¯•æ”¹è¿›çš„åˆ†å±‚ PCCheckï¼ˆæ”¯æŒé›¶æ‹·è´åˆ†å—å¼‚æ­¥ä¿å­˜ï¼‰"""
    
    print(f"\n{'='*80}")
    print(f"ğŸŸ£ å¼€å§‹æµ‹è¯•: æ”¹è¿›çš„åˆ†å±‚ PCCheck")
    if use_chunked_async:
        print(f"   ğŸš€ å¯ç”¨é›¶æ‹·è´åˆ†å—å¼‚æ­¥ä¿å­˜")
    print(f"{'='*80}")
    
    metrics = BenchmarkMetrics("Layerwise PCCheck (Improved)")
    
    # åˆ›å»ºåˆ†å±‚æ£€æŸ¥ç‚¹è®­ç»ƒå™¨
    print(f"ğŸ“ åˆå§‹åŒ–åˆ†å±‚è®­ç»ƒå™¨:")
    print(f"   - Threads: {num_threads}")
    print(f"   - Max async: {max_async}")
    print(f"   - Buffer size: {buffer_size_mb} MB")
    print(f"   - Batch size: {batch_size_mb} MB")
    print(f"   - Use monitor: {use_monitor}")
    if use_chunked_async:
        print(f"   - ğŸ”¥ Chunked async: True (chunk_size={chunk_size_mb}MB, workers={async_workers})")
    
    c_lib_path = "/home/linzhicheng/code/pccheck/checkpoint_eval/pccheck/libtest_ssd.so"
    
    # ä½¿ç”¨pccheckçš„initåˆ›å»ºgpuç©ºé—´
    trainer = LayerwiseCheckpointTrainer(
        model=model,
        optimizer_class=torch.optim.Adam,
        optimizer_kwargs={'lr': 0.001},
        checkpoint_dir=checkpoint_dir,
        buffer_size_mb=buffer_size_mb,
        use_pccheck=True,
        use_monitor=use_monitor,
        num_threads=num_threads,
        max_async=max_async,
        batch_size_mb=batch_size_mb,
        ratio=2.0,
        c_lib_path=c_lib_path,
        device=device,
        verbose=False,
        use_chunked_async=use_chunked_async,  # ğŸ”¥ å¯ç”¨åˆ†å—å¼‚æ­¥ä¿å­˜
        chunk_size_mb=chunk_size_mb,          # ğŸ”¥ ä¼ é€’å—å¤§å°
        async_workers=async_workers           # ğŸ”¥ ä¼ é€’å·¥ä½œçº¿ç¨‹æ•°
    )
    
    model.train()
    
    step = 0
    total_samples = 0
    start_time = time.time()
    
    data_iter = iter(train_loader)
    
    # ç”¨äºæµ‹é‡æ£€æŸ¥ç‚¹æ—¶é—´çš„å˜é‡
    last_checkpoint_step = 0
    checkpoint_start_time = None
    
    while step < num_steps:
        try:
            data, target = next(data_iter)
        except StopIteration:
            data_iter = iter(train_loader)
            data, target = next(data_iter)
        
        data, target = data.to(device), target.to(device)
        batch_size = data.size(0)
        
        # ğŸ”¥ åˆ¤æ–­æ˜¯å¦éœ€è¦ä¿å­˜æ£€æŸ¥ç‚¹
        need_checkpoint = (step % checkpoint_freq == 0 and step > 0)
        
        # è®­ç»ƒæ­¥ (åŒ…å«åˆ†å±‚æ£€æŸ¥ç‚¹ä¿å­˜)
        step_start = time.time()
        
        # æ£€æŸ¥ç‚¹ä¿å­˜å¼€å§‹æ—¶åˆ»
        if need_checkpoint:
            checkpoint_start_time = time.time()
            last_checkpoint_step = step
        
        # ğŸ”¥ ä½¿ç”¨ trainer çš„ train_stepï¼Œåªåœ¨éœ€è¦æ—¶å¯ç”¨æ£€æŸ¥ç‚¹å›è°ƒ
        loss_value = trainer.train_step(
            data, target, criterion, 
            enable_checkpoint=need_checkpoint  # ğŸ”¥ å…³é”®ï¼šæ§åˆ¶æ˜¯å¦è§¦å‘å›è°ƒ
        )
        
        # å¦‚æœæ˜¯æ£€æŸ¥ç‚¹æ­¥éª¤ï¼Œå®Œæˆæ£€æŸ¥ç‚¹
        if need_checkpoint:
            trainer.finalize_checkpoint()
            chk_time = (time.time() - checkpoint_start_time) * 1000
            metrics.add_checkpoint_time(chk_time)
            # å‡å°‘è¾“å‡ºé¢‘ç‡ï¼Œåªåœ¨æŸäº›æ­¥éª¤è¾“å‡º
            if step % (checkpoint_freq * 5) == 0:  # æ¯5æ¬¡æ£€æŸ¥ç‚¹è¾“å‡ºä¸€æ¬¡
                print(f"  âœ“ Step {step}: åˆ†å±‚ä¿å­˜å®Œæˆ ({chk_time:.2f} ms)")
        
        step_time = (time.time() - step_start) * 1000
        metrics.add_step_time(step_time)
        
        total_samples += batch_size
        step += 1
        
        # è®°å½•å†…å­˜
        if step % 10 == 0:
            metrics.record_memory()
    
    total_time = time.time() - start_time
    metrics.total_time = total_time
    metrics.num_samples = total_samples
    metrics.throughput = total_samples / total_time
    
    # å…³é—­è®­ç»ƒå™¨
    trainer.shutdown()
    
    return metrics


def benchmark_multistream_pccheck(
    model: nn.Module,
    train_loader: DataLoader,
    criterion,
    optimizer,
    device: str,
    checkpoint_freq: int,
    checkpoint_file: str,
    num_threads: int,
    max_async: int,
    num_layer_groups: int,
    num_steps: int = 100
) -> BenchmarkMetrics:
    """æµ‹è¯•å¤šæµå¹¶è¡Œ PCCheck"""
    
    print(f"\n{'='*80}")
    print(f"ğŸŸ¡ å¼€å§‹æµ‹è¯•: å¤šæµå¹¶è¡Œ PCCheck")
    print(f"{'='*80}")
    
    metrics = BenchmarkMetrics("Multistream PCCheck")
    model.train()
    
    # åˆå§‹åŒ– PCCheck Monitor
    print(f"ğŸ“ åˆå§‹åŒ–å¤šæµ PCCheck:")
    
    # âœ… ä¿®å¤ï¼šä½¿ç”¨ do_opt_step=True æ¥åˆå§‹åŒ–ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆexp_avg, exp_avg_sqï¼‰
    # è¿™ç¡®ä¿ gpu_ar åŒ…å«å®Œæ•´çš„ 4 ä»½æ•°æ®ï¼šparam, grad, exp_avg, exp_avg_sq
    gpu_ar, total_size = initialize(model, [optimizer], do_opt_step=True)
    
    print(f"   - æ¨¡å‹å¤§å°: {total_size/1e6:.2f}M å‚æ•°")
    print(f"   - Threads: {num_threads}, Max async: {max_async}")
    print(f"   - å±‚åˆ†ç»„æ•°: {num_layer_groups}")
    
    # è®¾ç½®å­˜å‚¨
    set_storage(model, [optimizer], gpu_ar)
    torch.cuda.empty_cache()
    
    # âœ… ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„ build_param_layout å‡½æ•°ï¼Œè€Œä¸æ˜¯ build_test_layout_from_model
    # build_param_layout ä½¿ç”¨ model_size è€Œä¸æ˜¯ total_size æ¥è®¡ç®—åç§»
    param_layout = build_param_layout(model, optimizer)
    
    # åˆ›å»ºå¤šæµæ£€æŸ¥ç‚¹
    c_lib_path = "/home/linzhicheng/code/pccheck/checkpoint_eval/pccheck/libtest_ssd.so"
    checkpoint = MultiStreamCheckpoint(
        param_layout=param_layout,
        gpu_ar=gpu_ar,
        total_size=total_size,
        num_streams=4,
        num_threads=num_threads,
        num_layer_groups=num_layer_groups,
        lib_path=c_lib_path,
        filename=checkpoint_file,
        max_async=max_async
    )
    
    # åˆ›å»ºMultiStreamOptimizeråŒ…è£…å™¨
    ms_optimizer = checkpoint.create_optimizer(optimizer, model)
    
    # è®¾ç½®æ•°æ®å¤§å°
    metrics.data_size_gb = total_size * 4 / 1e9
    
    # è®¾ç½®IOç»Ÿè®¡å›è°ƒ
    def io_callback(save_time_sec, throughput_gbps):
        metrics.add_io_stats(save_time_sec, throughput_gbps)
    
    checkpoint.set_io_callback(io_callback)
    
    step = 0
    total_samples = 0
    start_time = time.time()
    
    data_iter = iter(train_loader)
    
    while step < num_steps:
        try:
            data, target = next(data_iter)
        except StopIteration:
            data_iter = iter(train_loader)
            data, target = next(data_iter)
        
        data, target = data.to(device), target.to(device)
        batch_size = data.size(0)
        
        # è®­ç»ƒæ­¥
        step_start = time.time()
        step += 1
        
        ms_optimizer.zero_grad()
        output = model(data)
        loss = criterion(output.view(-1, output.size(-1)), target.view(-1))
        loss.backward()
        
        # æ£€æŸ¥ç‚¹ä¿å­˜ï¼ˆè¾¹æ›´æ–°è¾¹ä¿å­˜ï¼‰
        if step % checkpoint_freq == 0:
            chk_start = time.time()
            
            # ä½¿ç”¨å¤šæµ PCCheck è¾¹æ›´æ–°è¾¹ä¿å­˜ï¼ˆå¼‚æ­¥æ¨¡å¼ï¼Œå…¬å¹³å¯¹æ¯”ï¼‰
            # 1. å¼€å§‹æ£€æŸ¥ç‚¹ï¼ˆé€šè¿‡OptimizerWrapperï¼Œå®ƒä¼šåˆ›å»ºå®é™…çš„MultiStreamOptimizerï¼‰
            ms_optimizer.begin_checkpoint()
            
            # 2. åˆ†å±‚æ›´æ–°å‚æ•°ï¼ˆè‡ªåŠ¨è§¦å‘å¼‚æ­¥ä¿å­˜ï¼‰
            ms_optimizer.step_with_callback()
            
            # 3. å®Œæˆæ£€æŸ¥ç‚¹ï¼ˆå¼‚æ­¥æ¨¡å¼ï¼šä¸ç­‰å¾…ï¼Œåå°ä¿å­˜ï¼‰
            ms_optimizer.finalize_checkpoint(wait=False)
            
            raw_chk_time = (time.time() - chk_start) * 1000
            
            # ä¼°ç®—çº¯æ£€æŸ¥ç‚¹å¼€é”€ï¼šå‡å»å¹³å‡è®­ç»ƒæ­¥æ—¶é—´ï¼ˆå› ä¸ºstep_with_callbackåŒ…å«äº†å‚æ•°æ›´æ–°ï¼‰
            avg_step_time = 0
            if len(metrics.training_step_times) > 0:
                avg_step_time = sum(metrics.training_step_times) / len(metrics.training_step_times)
            
            # åªæœ‰å½“raw_chk_timeæ˜æ˜¾å¤§äºavg_step_timeæ—¶æ‰è®¡ç®—å¼€é”€
            # å¦åˆ™è®¤ä¸ºå¼€é”€æå°ï¼ˆè¢«å™ªå£°æ©ç›–ï¼‰
            overhead = max(0.0, raw_chk_time - avg_step_time)
            
            metrics.add_checkpoint_time(overhead)
            # å‡å°‘è¾“å‡ºé¢‘ç‡
            if step % (checkpoint_freq * 5) == 0:  # æ¯5æ¬¡æ£€æŸ¥ç‚¹è¾“å‡ºä¸€æ¬¡
                print(f"  âœ“ Step {step}: å¤šæµPCCheck è¾¹æ›´æ–°è¾¹ä¿å­˜ï¼ˆå¼‚æ­¥ï¼‰(æ€»è€—æ—¶: {raw_chk_time:.2f} ms, ä¼°ç®—å¼€é”€: {overhead:.2f} ms)")
        else:
            # éæ£€æŸ¥ç‚¹æ­¥éª¤ï¼šæ­£å¸¸æ›´æ–°ï¼ˆä¸è§¦å‘å›è°ƒï¼‰
            ms_optimizer.step()
        
        step_time = (time.time() - step_start) * 1000
        metrics.add_step_time(step_time)
        
        total_samples += batch_size
        
        # è®°å½•å†…å­˜
        if step % 10 == 0:
            metrics.record_memory()
    
    # å…³é—­ checkpointï¼ˆä¼šç­‰å¾…æ‰€æœ‰åå°å¼‚æ­¥ä¿å­˜å®Œæˆï¼‰
    checkpoint.shutdown()
    total_time = time.time() - start_time
    metrics.total_time = total_time
    metrics.num_samples = total_samples
    metrics.throughput = total_samples / total_time
    
    return metrics


def compare_methods(results: Dict[str, BenchmarkMetrics], output_file: str):
    """å¯¹æ¯”ä¸åŒæ–¹æ³•çš„ç»“æœ"""
    
    print(f"\n{'='*80}")
    print(f"ğŸ“Š å®éªŒç»“æœå¯¹æ¯”")
    print(f"{'='*80}\n")
    
    # æ”¶é›†ç»Ÿè®¡æ•°æ®
    all_stats = {}
    for name, metrics in results.items():
        all_stats[name] = metrics.compute_statistics()
    
    # æ‰“å°å¯¹æ¯”è¡¨æ ¼
    method_names = ['ä¼ ç»Ÿ', 'åŸå§‹PCCheck', 'åˆ†å±‚PCCheck', 'å¤šæµPCCheck']
    header = f"{'æŒ‡æ ‡':<30} " + " ".join([f"{name:<20}" for name in method_names[:len(all_stats)]])
    print(header)
    print(f"{'-'*90}")
    
    # åŸºå‡†æ–¹æ³•
    baseline_name = "Traditional PyTorch Checkpoint"
    baseline = all_stats.get(baseline_name)
    
    # ååé‡å¯¹æ¯”
    print(f"\nğŸš€ ååé‡ (samples/sec):")
    for name, stats in all_stats.items():
        throughput = stats['throughput']['samples_per_sec']
        if baseline and name != baseline_name:
            speedup = throughput / baseline['throughput']['samples_per_sec']
            print(f"  {name:<30}: {throughput:>10.2f}  (speedup: {speedup:.2f}x)")
        else:
            print(f"  {name:<30}: {throughput:>10.2f}  (baseline)")
    
    # æ£€æŸ¥ç‚¹å¼€é”€å¯¹æ¯”
    print(f"\nğŸ’¾ æ£€æŸ¥ç‚¹å¼€é”€:")
    for name, stats in all_stats.items():
        overhead = stats['checkpoint_overhead_percent']
        mean_time = stats['checkpoint']['mean_ms']
        if baseline and name != baseline_name:
            reduction = (1 - overhead / baseline['checkpoint_overhead_percent']) * 100
            print(f"  {name:<30}: {overhead:>6.2f}%  (å¹³å‡ {mean_time:>7.2f}ms, é™ä½ {reduction:>5.1f}%)")
        else:
            print(f"  {name:<30}: {overhead:>6.2f}%  (å¹³å‡ {mean_time:>7.2f}ms, baseline)")
    
    # å†…å­˜ä½¿ç”¨å¯¹æ¯”
    print(f"\nğŸ’» å³°å€¼å†…å­˜ (GB):")
    for name, stats in all_stats.items():
        cpu_mem = stats['memory']['peak_cpu_gb']
        gpu_mem = stats['memory']['peak_gpu_gb']
        print(f"  {name:<30}: CPU {cpu_mem:>6.2f}, GPU {gpu_mem:>6.2f}")
    
    # IOä¼ è¾“é€Ÿç‡å¯¹æ¯”
    print(f"\nğŸ’¾ IOä¼ è¾“æ€§èƒ½:")
    for name, stats in all_stats.items():
        io_perf = stats['io_performance']
        if io_perf['count'] > 0:
            print(f"  {name:<30}:")
            print(f"    æ•°æ®å¤§å°: {io_perf['data_size_gb']:.2f} GB")
            print(f"    å¹³å‡ä¼ è¾“é€Ÿç‡: {io_perf['mean_io_throughput_gbps']:.2f} GB/s")
            print(f"    ä¼ è¾“é€Ÿç‡èŒƒå›´: [{io_perf['min_io_throughput_gbps']:.2f}, {io_perf['max_io_throughput_gbps']:.2f}] GB/s")
            print(f"    å¹³å‡å®é™…ä¿å­˜æ—¶é—´: {io_perf['mean_save_time_sec']:.2f} ç§’")
        else:
            print(f"  {name:<30}: æš‚æ— IOç»Ÿè®¡ï¼ˆå¼‚æ­¥ä¿å­˜ä¸­ï¼‰")
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    output_data = {
        'timestamp': datetime.now().isoformat(),
        'results': all_stats
    }
    
    with open(output_file, 'w') as f:
        json.dump(output_data, f, indent=2)
    
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")


def main():
    parser = argparse.ArgumentParser(description='PCCheck æ”¹è¿›æ•ˆæœå¯¹æ¯”å®éªŒ')
    
    # æ¨¡å‹é…ç½®
    parser.add_argument('--vocab-size', type=int, default=10000, help='è¯æ±‡è¡¨å¤§å°')
    parser.add_argument('--d-model', type=int, default=512, help='æ¨¡å‹ç»´åº¦')
    parser.add_argument('--nhead', type=int, default=8, help='æ³¨æ„åŠ›å¤´æ•°')
    parser.add_argument('--num-layers', type=int, default=6, help='Transformer å±‚æ•°')
    parser.add_argument('--dim-feedforward', type=int, default=2048, help='å‰é¦ˆç½‘ç»œç»´åº¦')
    
    # è®­ç»ƒé…ç½®
    parser.add_argument('--num-samples', type=int, default=1000, help='è®­ç»ƒæ ·æœ¬æ•°')
    parser.add_argument('--seq-len', type=int, default=128, help='åºåˆ—é•¿åº¦')
    parser.add_argument('--batch-size', type=int, default=16, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--num-steps', type=int, default=100, help='è®­ç»ƒæ­¥æ•°')
    parser.add_argument('--checkpoint-freq', type=int, default=10, help='æ£€æŸ¥ç‚¹ä¿å­˜é¢‘ç‡')
    
    # PCCheck é…ç½®
    parser.add_argument('--num-threads', type=int, default=8, help='PCCheck çº¿ç¨‹æ•°')
    parser.add_argument('--max-async', type=int, default=4, help='æœ€å¤§å¹¶å‘æ£€æŸ¥ç‚¹æ•°')
    parser.add_argument('--buffer-size-mb', type=float, default=50.0, help='ç¼“å†²åŒºå¤§å° (MB)')
    parser.add_argument('--batch-size-mb', type=float, default=100.0, help='PCCheck æ‰¹æ¬¡å¤§å° (MB)')
    parser.add_argument('--use-monitor', action='store_true', help='ä½¿ç”¨ Monitor æ¨¡å¼')
    
    # ğŸ”¥ é›¶æ‹·è´åˆ†å—å¼‚æ­¥ä¿å­˜é…ç½®
    parser.add_argument('--use-chunked-async', action='store_true', default=True, 
                        help='ä½¿ç”¨é›¶æ‹·è´åˆ†å—å¼‚æ­¥ä¿å­˜ï¼ˆé»˜è®¤å¯ç”¨ï¼‰')
    parser.add_argument('--chunk-size-mb', type=float, default=512.0, 
                        help='åˆ†å—å¤§å° (MB)ï¼Œé»˜è®¤512MB')
    parser.add_argument('--async-workers', type=int, default=4, 
                        help='å¼‚æ­¥ä¿å­˜å·¥ä½œçº¿ç¨‹æ•°ï¼Œé»˜è®¤4')
    
    # å®éªŒé…ç½®
    parser.add_argument('--methods', nargs='+', default=['traditional', 'original', 'layerwise', 'multistream'],
                        choices=['traditional', 'original', 'layerwise', 'multistream'],
                        help='è¦æµ‹è¯•çš„æ–¹æ³•')
    parser.add_argument('--num-layer-groups', type=int, default=4, help='å¤šæµPCCheckçš„å±‚åˆ†ç»„æ•°')
    parser.add_argument('--output-dir', type=str, default='./benchmark_results',
                        help='ç»“æœè¾“å‡ºç›®å½•')
    parser.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu',
                        help='è®­ç»ƒè®¾å¤‡')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    print(f"\n{'='*80}")
    print(f"ğŸ”¬ PCCheck æ”¹è¿›æ•ˆæœå¯¹æ¯”å®éªŒ")
    print(f"{'='*80}")
    print(f"ğŸ“… æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ–¥ï¸  è®¾å¤‡: {args.device}")
    print(f"ğŸ“ é…ç½®:")
    print(f"   - æ¨¡å‹: Transformer (d={args.d_model}, layers={args.num_layers})")
    print(f"   - æ•°æ®: {args.num_samples} samples, seq_len={args.seq_len}")
    print(f"   - è®­ç»ƒ: {args.num_steps} steps, batch_size={args.batch_size}")
    print(f"   - æ£€æŸ¥ç‚¹é¢‘ç‡: æ¯ {args.checkpoint_freq} æ­¥")
    print(f"   - æµ‹è¯•æ–¹æ³•: {', '.join(args.methods)}")
    if 'layerwise' in args.methods and args.use_chunked_async:
        print(f"   - ğŸ”¥ é›¶æ‹·è´åˆ†å—å¼‚æ­¥ä¿å­˜: å·²å¯ç”¨")
        print(f"     â€¢ å—å¤§å°: {args.chunk_size_mb} MB")
        print(f"     â€¢ å¼‚æ­¥å·¥ä½œçº¿ç¨‹: {args.async_workers}")
    print(f"{'='*80}\n")
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = create_synthetic_dataset(
        num_samples=args.num_samples,
        seq_len=args.seq_len,
        vocab_size=args.vocab_size
    )
    train_loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)
    
    # æŸå¤±å‡½æ•°
    criterion = nn.CrossEntropyLoss()
    
    # å­˜å‚¨ç»“æœ
    results = {}
    
    # æµ‹è¯•ä¼ ç»Ÿæ–¹æ³•
    if 'traditional' in args.methods:
        model = TestModel(
            vocab_size=args.vocab_size,
            d_model=args.d_model,
            nhead=args.nhead,
            num_layers=args.num_layers,
            dim_feedforward=args.dim_feedforward
        ).to(args.device)
        
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        
        checkpoint_dir = os.path.join(args.output_dir, f'traditional_{timestamp}')
        
        metrics = benchmark_traditional_checkpoint(
            model, train_loader, criterion, optimizer,
            args.device, args.checkpoint_freq, checkpoint_dir, args.num_steps
        )
        metrics.print_summary()
        results['Traditional PyTorch Checkpoint'] = metrics
        
        # æ¸…ç†
        del model, optimizer
        torch.cuda.empty_cache()
    
    # æµ‹è¯•åŸå§‹ PCCheck
    if 'original' in args.methods:
        model = TestModel(
            vocab_size=args.vocab_size,
            d_model=args.d_model,
            nhead=args.nhead,
            num_layers=args.num_layers,
            dim_feedforward=args.dim_feedforward
        ).to(args.device)
        
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        
        checkpoint_file = os.path.join(args.output_dir, f'original_{timestamp}.chk')
        
        metrics = benchmark_original_pccheck(
            model, train_loader, criterion, optimizer,
            args.device, args.checkpoint_freq, checkpoint_file,
            args.num_threads, args.max_async, args.num_steps
        )
        metrics.print_summary()
        results['Original PCCheck'] = metrics
        
        # æ¸…ç†
        del model, optimizer
        torch.cuda.empty_cache()
    
    # æµ‹è¯•åˆ†å±‚ PCCheck
    if 'layerwise' in args.methods:
        model = TestModel(
            vocab_size=args.vocab_size,
            d_model=args.d_model,
            nhead=args.nhead,
            num_layers=args.num_layers,
            dim_feedforward=args.dim_feedforward
        ).to(args.device)
        
        checkpoint_dir = os.path.join(args.output_dir, f'layerwise_{timestamp}')
        
        metrics = benchmark_layerwise_pccheck(
            model, train_loader, criterion,
            args.device, checkpoint_dir,
            args.num_threads, args.max_async,
            args.buffer_size_mb, args.batch_size_mb,
            True, args.checkpoint_freq, args.num_steps,
            use_chunked_async=args.use_chunked_async,  # ğŸ”¥ ä¼ é€’é›¶æ‹·è´åˆ†å—å‚æ•°
            chunk_size_mb=args.chunk_size_mb,
            async_workers=args.async_workers
        )
        metrics.print_summary()
        results['Layerwise PCCheck (Improved)'] = metrics
        
        # æ¸…ç†
        del model
        torch.cuda.empty_cache()
    
    # æµ‹è¯•å¤šæµ PCCheck
    if 'multistream' in args.methods:
        model = TestModel(
            vocab_size=args.vocab_size,
            d_model=args.d_model,
            nhead=args.nhead,
            num_layers=args.num_layers,
            dim_feedforward=args.dim_feedforward
        ).to(args.device)
        
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        
        checkpoint_file = os.path.join(args.output_dir, f'multistream_{timestamp}.chk')
        
        metrics = benchmark_multistream_pccheck(
            model, train_loader, criterion, optimizer,
            args.device, args.checkpoint_freq, checkpoint_file,
            2, args.max_async, args.num_layer_groups, args.num_steps
        )
        metrics.print_summary()
        results['Multistream PCCheck'] = metrics
        
        # æ¸…ç†
        del model, optimizer
        torch.cuda.empty_cache()
    
    # å¯¹æ¯”ç»“æœ
    if len(results) > 1:
        output_file = os.path.join(args.output_dir, f'comparison_{timestamp}.json')
        compare_methods(results, output_file)
    
    print(f"\nâœ… å®éªŒå®Œæˆï¼")


if __name__ == "__main__":
    main()
