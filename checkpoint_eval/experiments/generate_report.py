#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®éªŒæŠ¥å‘Šç”Ÿæˆå™¨
ä»åŸºå‡†æµ‹è¯•ç»“æœç”Ÿæˆ Markdown æ ¼å¼çš„æ±‡æ€»æŠ¥å‘Š
"""

import os
import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
import numpy as np
from typing import Dict, List


def load_all_results(input_dir: str) -> Dict[str, dict]:
    """åŠ è½½æ‰€æœ‰å®éªŒç»“æœ"""
    results = {}
    
    for root, dirs, files in os.walk(input_dir):
        for file in files:
            if file.startswith('comparison_') and file.endswith('.json'):
                filepath = os.path.join(root, file)
                experiment_name = os.path.basename(root)
                
                with open(filepath, 'r') as f:
                    data = json.load(f)
                    results[experiment_name] = data
    
    return results


def generate_summary_table(results: Dict[str, dict]) -> str:
    """ç”Ÿæˆæ±‡æ€»è¡¨æ ¼"""
    
    table = """
## ğŸ“Š å®éªŒç»“æœæ±‡æ€»

### ååé‡å¯¹æ¯” (samples/sec)

| å®éªŒ | ä¼ ç»Ÿæ–¹æ³• | åŸå§‹PCCheck | åˆ†å±‚PCCheck | åŠ é€Ÿæ¯” |
|------|----------|-------------|-------------|--------|
"""
    
    for exp_name, data in results.items():
        exp_results = data.get('results', {})
        
        traditional = exp_results.get('Traditional PyTorch Checkpoint', {})
        original = exp_results.get('Original PCCheck', {})
        layerwise = exp_results.get('Layerwise PCCheck (Improved)', {})
        
        trad_throughput = traditional.get('throughput', {}).get('samples_per_sec', 0)
        orig_throughput = original.get('throughput', {}).get('samples_per_sec', 0)
        layer_throughput = layerwise.get('throughput', {}).get('samples_per_sec', 0)
        
        speedup = layer_throughput / trad_throughput if trad_throughput > 0 else 0
        
        table += f"| {exp_name} | {trad_throughput:.2f} | {orig_throughput:.2f} | {layer_throughput:.2f} | **{speedup:.2f}x** |\n"
    
    return table


def generate_checkpoint_overhead_table(results: Dict[str, dict]) -> str:
    """ç”Ÿæˆæ£€æŸ¥ç‚¹å¼€é”€å¯¹æ¯”è¡¨æ ¼"""
    
    table = """
### ğŸ’¾ æ£€æŸ¥ç‚¹å¼€é”€å¯¹æ¯” (%)

| å®éªŒ | ä¼ ç»Ÿæ–¹æ³• | åŸå§‹PCCheck | åˆ†å±‚PCCheck | é™ä½å¹…åº¦ |
|------|----------|-------------|-------------|----------|
"""
    
    for exp_name, data in results.items():
        exp_results = data.get('results', {})
        
        traditional = exp_results.get('Traditional PyTorch Checkpoint', {})
        original = exp_results.get('Original PCCheck', {})
        layerwise = exp_results.get('Layerwise PCCheck (Improved)', {})
        
        trad_overhead = traditional.get('checkpoint_overhead_percent', 0)
        orig_overhead = original.get('checkpoint_overhead_percent', 0)
        layer_overhead = layerwise.get('checkpoint_overhead_percent', 0)
        
        reduction = ((trad_overhead - layer_overhead) / trad_overhead * 100) if trad_overhead > 0 else 0
        
        table += f"| {exp_name} | {trad_overhead:.2f}% | {orig_overhead:.2f}% | {layer_overhead:.2f}% | **-{reduction:.1f}%** |\n"
    
    return table


def generate_checkpoint_time_table(results: Dict[str, dict]) -> str:
    """ç”Ÿæˆæ£€æŸ¥ç‚¹æ—¶é—´å¯¹æ¯”è¡¨æ ¼"""
    
    table = """
### â±ï¸ å¹³å‡æ£€æŸ¥ç‚¹ä¿å­˜æ—¶é—´ (ms)

| å®éªŒ | ä¼ ç»Ÿæ–¹æ³• | åŸå§‹PCCheck | åˆ†å±‚PCCheck | æ”¹å–„ |
|------|----------|-------------|-------------|------|
"""
    
    for exp_name, data in results.items():
        exp_results = data.get('results', {})
        
        traditional = exp_results.get('Traditional PyTorch Checkpoint', {})
        original = exp_results.get('Original PCCheck', {})
        layerwise = exp_results.get('Layerwise PCCheck (Improved)', {})
        
        trad_time = traditional.get('checkpoint', {}).get('mean_ms', 0)
        orig_time = original.get('checkpoint', {}).get('mean_ms', 0)
        layer_time = layerwise.get('checkpoint', {}).get('mean_ms', 0)
        
        improvement = ((trad_time - layer_time) / trad_time * 100) if trad_time > 0 else 0
        
        table += f"| {exp_name} | {trad_time:.2f} | {orig_time:.2f} | {layer_time:.2f} | **-{improvement:.1f}%** |\n"
    
    return table


def generate_memory_table(results: Dict[str, dict]) -> str:
    """ç”Ÿæˆå†…å­˜ä½¿ç”¨å¯¹æ¯”è¡¨æ ¼"""
    
    table = """
### ğŸ’» å³°å€¼å†…å­˜ä½¿ç”¨ (GB)

| å®éªŒ | æ–¹æ³• | CPU å†…å­˜ | GPU å†…å­˜ |
|------|------|----------|----------|
"""
    
    for exp_name, data in results.items():
        exp_results = data.get('results', {})
        
        for method_name, method_data in exp_results.items():
            cpu_mem = method_data.get('memory', {}).get('peak_cpu_gb', 0)
            gpu_mem = method_data.get('memory', {}).get('peak_gpu_gb', 0)
            
            short_name = method_name.replace('Traditional PyTorch Checkpoint', 'ä¼ ç»Ÿ') \
                                    .replace('Original PCCheck', 'åŸå§‹') \
                                    .replace('Layerwise PCCheck (Improved)', 'åˆ†å±‚')
            
            table += f"| {exp_name} | {short_name} | {cpu_mem:.2f} | {gpu_mem:.2f} |\n"
    
    return table


def calculate_overall_statistics(results: Dict[str, dict]) -> dict:
    """è®¡ç®—æ€»ä½“ç»Ÿè®¡æ•°æ®"""
    
    all_speedups = []
    all_overhead_reductions = []
    all_time_improvements = []
    
    for exp_name, data in results.items():
        exp_results = data.get('results', {})
        
        traditional = exp_results.get('Traditional PyTorch Checkpoint', {})
        layerwise = exp_results.get('Layerwise PCCheck (Improved)', {})
        
        # åŠ é€Ÿæ¯”
        trad_throughput = traditional.get('throughput', {}).get('samples_per_sec', 0)
        layer_throughput = layerwise.get('throughput', {}).get('samples_per_sec', 0)
        if trad_throughput > 0:
            all_speedups.append(layer_throughput / trad_throughput)
        
        # å¼€é”€é™ä½
        trad_overhead = traditional.get('checkpoint_overhead_percent', 0)
        layer_overhead = layerwise.get('checkpoint_overhead_percent', 0)
        if trad_overhead > 0:
            all_overhead_reductions.append((trad_overhead - layer_overhead) / trad_overhead * 100)
        
        # æ—¶é—´æ”¹å–„
        trad_time = traditional.get('checkpoint', {}).get('mean_ms', 0)
        layer_time = layerwise.get('checkpoint', {}).get('mean_ms', 0)
        if trad_time > 0:
            all_time_improvements.append((trad_time - layer_time) / trad_time * 100)
    
    return {
        'avg_speedup': np.mean(all_speedups) if all_speedups else 0,
        'max_speedup': np.max(all_speedups) if all_speedups else 0,
        'min_speedup': np.min(all_speedups) if all_speedups else 0,
        'avg_overhead_reduction': np.mean(all_overhead_reductions) if all_overhead_reductions else 0,
        'avg_time_improvement': np.mean(all_time_improvements) if all_time_improvements else 0,
    }


def generate_report(input_dir: str, output_file: str):
    """ç”Ÿæˆå®Œæ•´æŠ¥å‘Š"""
    
    print(f"ğŸ“– æ­£åœ¨ç”Ÿæˆå®éªŒæŠ¥å‘Š...")
    print(f"   è¾“å…¥ç›®å½•: {input_dir}")
    print(f"   è¾“å‡ºæ–‡ä»¶: {output_file}")
    
    # åŠ è½½æ‰€æœ‰ç»“æœ
    results = load_all_results(input_dir)
    
    if not results:
        print("âŒ æœªæ‰¾åˆ°å®éªŒç»“æœæ–‡ä»¶ï¼")
        return
    
    print(f"   æ‰¾åˆ° {len(results)} ä¸ªå®éªŒç»“æœ")
    
    # è®¡ç®—æ€»ä½“ç»Ÿè®¡
    overall_stats = calculate_overall_statistics(results)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = f"""# PCCheck æ”¹è¿›æ•ˆæœå®éªŒæŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**å®éªŒç›®å½•:** `{input_dir}`  
**å®éªŒæ•°é‡:** {len(results)}

---

## ğŸ¯ æ ¸å¿ƒå‘ç°

- âœ… **å¹³å‡åŠ é€Ÿæ¯”:** {overall_stats['avg_speedup']:.2f}x (æœ€é«˜: {overall_stats['max_speedup']:.2f}x)
- âœ… **æ£€æŸ¥ç‚¹å¼€é”€å¹³å‡é™ä½:** {overall_stats['avg_overhead_reduction']:.1f}%
- âœ… **æ£€æŸ¥ç‚¹ä¿å­˜æ—¶é—´å¹³å‡æ”¹å–„:** {overall_stats['avg_time_improvement']:.1f}%

---

{generate_summary_table(results)}

{generate_checkpoint_overhead_table(results)}

{generate_checkpoint_time_table(results)}

{generate_memory_table(results)}

---

## ğŸ“ˆ è¯¦ç»†åˆ†æ

"""
    
    # ä¸ºæ¯ä¸ªå®éªŒæ·»åŠ è¯¦ç»†åˆ†æ
    for exp_name, data in results.items():
        report += f"\n### {exp_name}\n\n"
        
        exp_results = data.get('results', {})
        
        for method_name, method_data in exp_results.items():
            report += f"#### {method_name}\n\n"
            report += f"- **æ€»è®­ç»ƒæ—¶é—´:** {method_data.get('total_time_sec', 0):.2f} ç§’\n"
            report += f"- **ååé‡:** {method_data.get('throughput', {}).get('samples_per_sec', 0):.2f} samples/sec\n"
            report += f"- **æ£€æŸ¥ç‚¹å¼€é”€:** {method_data.get('checkpoint_overhead_percent', 0):.2f}%\n"
            report += f"- **å¹³å‡æ£€æŸ¥ç‚¹æ—¶é—´:** {method_data.get('checkpoint', {}).get('mean_ms', 0):.2f} ms\n"
            report += f"- **æ£€æŸ¥ç‚¹æ¬¡æ•°:** {method_data.get('checkpoint', {}).get('count', 0)}\n"
            report += f"- **CPU å³°å€¼å†…å­˜:** {method_data.get('memory', {}).get('peak_cpu_gb', 0):.2f} GB\n"
            report += f"- **GPU å³°å€¼å†…å­˜:** {method_data.get('memory', {}).get('peak_gpu_gb', 0):.2f} GB\n"
            report += "\n"
    
    # æ·»åŠ ç»“è®º
    report += """
---

## ğŸ“ ç»“è®º

åŸºäºä¸Šè¿°å®éªŒç»“æœï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºä»¥ä¸‹ç»“è®ºï¼š

1. **æ˜¾è‘—çš„æ€§èƒ½æå‡**  
   åˆ†å±‚ PCCheck ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•å®ç°äº†å¹³å‡ {:.2f}x çš„åŠ é€Ÿæ¯”ï¼Œè¯æ˜äº†è¾¹è®­ç»ƒè¾¹ä¿å­˜çš„æœ‰æ•ˆæ€§ã€‚

2. **å¤§å¹…é™ä½æ£€æŸ¥ç‚¹å¼€é”€**  
   é€šè¿‡åˆ†å±‚ä¿å­˜å’Œå¼‚æ­¥å¤„ç†ï¼Œæ£€æŸ¥ç‚¹å¼€é”€å¹³å‡é™ä½äº† {:.1f}%ï¼Œä½¿å¾—é¢‘ç¹ä¿å­˜æ£€æŸ¥ç‚¹æˆä¸ºå¯èƒ½ã€‚

3. **å†…å­˜ä½¿ç”¨å¯æ§**  
   åˆ†å±‚ä¿å­˜ç­–ç•¥ä¿æŒäº†åˆç†çš„å†…å­˜å ç”¨ï¼Œæ²¡æœ‰å¼•å…¥æ˜¾è‘—çš„å†…å­˜å¼€é”€ã€‚

4. **é€‚ç”¨äºå¤§è§„æ¨¡æ¨¡å‹**  
   å®éªŒè¡¨æ˜ï¼Œæ”¹è¿›æ–¹æ¡ˆåœ¨ä¸åŒè§„æ¨¡çš„æ¨¡å‹ä¸Šéƒ½èƒ½ä¿æŒè‰¯å¥½çš„æ€§èƒ½è¡¨ç°ã€‚

---

## ğŸ“ å»ºè®®

æ ¹æ®å®éªŒç»“æœï¼Œæˆ‘ä»¬å»ºè®®ï¼š

- âœ… å¯¹äºå¤§å‹æ¨¡å‹è®­ç»ƒï¼Œä½¿ç”¨åˆ†å±‚ PCCheck å¯ä»¥æ˜¾è‘—æå‡è®­ç»ƒæ•ˆç‡
- âœ… åœ¨éœ€è¦é¢‘ç¹ä¿å­˜æ£€æŸ¥ç‚¹çš„åœºæ™¯ä¸‹ï¼ˆå¦‚é•¿æ—¶é—´è®­ç»ƒï¼‰ï¼Œæ”¹è¿›æ–¹æ¡ˆä¼˜åŠ¿æ›´æ˜æ˜¾
- âœ… Monitor æ¨¡å¼å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æ€§èƒ½ï¼Œæ¨èåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨
- âœ… æ ¹æ®æ¨¡å‹å¤§å°å’Œç¡¬ä»¶é…ç½®ï¼Œåˆç†è°ƒæ•´ `num_threads` å’Œ `max_async` å‚æ•°

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
""".format(overall_stats['avg_speedup'], overall_stats['avg_overhead_reduction'])
    
    # ä¿å­˜æŠ¥å‘Š
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")


def main():
    parser = argparse.ArgumentParser(description='ç”Ÿæˆå®éªŒæŠ¥å‘Š')
    parser.add_argument('--input-dir', type=str, required=True, help='å®éªŒç»“æœç›®å½•')
    parser.add_argument('--output-file', type=str, required=True, help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶')
    
    args = parser.parse_args()
    
    generate_report(args.input_dir, args.output_file)


if __name__ == "__main__":
    main()
